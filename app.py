#!/usr/bin/env python3
"""
Reviews Analyzer v2.0 ENTERPRISE EDITION
Supports: Trustpilot, Google Reviews, TripAdvisor, Yelp (via Extended Reviews), Reddit
Advanced Analytics: Multi-Dimensional Sentiment, ABSA, Topic Modeling, Customer Journey
Autore: Mari
"""

import streamlit as st
import pandas as pd
import requests
import time
import json
import re
import numpy as np
from datetime import datetime
import logging
from docx import Document
from openai import OpenAI
from collections import Counter
import os
from urllib.parse import urlparse
import threading
from typing import Dict, List, Optional
from dataclasses import dataclass
import io
import zipfile

# ============================================================================
# CONFIGURAZIONE PAGINA (DEVE ESSERE IL PRIMO COMANDO STREAMLIT)
# ============================================================================
st.set_page_config(
    page_title="Review NLZYR",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# GESTIONE CREDENZIALI (ROBUSTA)
# ============================================================================
DFSEO_LOGIN = ""
DFSEO_PASS = ""
OPENAI_API_KEY = ""
GEMINI_API_KEY = ""
credentials_loaded = False

try:
    DFSEO_LOGIN = st.secrets["dfseo_login"]
    DFSEO_PASS = st.secrets["dfseo_pass"]
    OPENAI_API_KEY = st.secrets["openai_api_key"]
    GEMINI_API_KEY = st.secrets["gemini_api_key"]
    credentials_loaded = True
except (KeyError, FileNotFoundError):
    st.error(
        "**ERRORE CRITICO: CREDENZIALI MANCANTI!**\n\n"
        "L'applicazione non pu√≤ avviarsi perch√© non trova le credenziali.\n\n"
        "**Soluzione:**\n"
        "1. Se esegui l'app su Streamlit Cloud, vai su 'Settings' > 'Secrets'.\n"
        "2. Incolla il seguente testo, sostituendo i valori:"
    )
    st.code(
        '# Incolla questo nella sezione Secrets di Streamlit Cloud\n'
        'dfseo_login = "la_tua_email@esempio.com"\n'
        'dfseo_pass = "la_tua_password_dataforseo"\n'
        'openai_api_key = "sk-..."\n'
        'gemini_api_key = "AIzaSy..."',
        language='toml'
    )
    st.warning("**Importante:** Le chiavi (es. `dfseo_login`) devono essere in **minuscolo**.")
    st.stop()

# ============================================================================
# IMPORT LIBRERIE PESANTI (DOPO LE CREDENZIALI)
# ============================================================================
PLOTLY_AVAILABLE = False
ML_CORE_AVAILABLE = False
SENTENCE_TRANSFORMERS_AVAILABLE = False
HDBSCAN_AVAILABLE = False
BERTOPIC_AVAILABLE = False

try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.cluster import KMeans
    ML_CORE_AVAILABLE = True
    import networkx as nx
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
    import hdbscan
    HDBSCAN_AVAILABLE = True
    from bertopic import BERTopic
    BERTOPIC_AVAILABLE = True
except ImportError as e:
    st.error(f"**ERRORE: LIBRERIA MANCANTE!**\n\nL'applicazione non pu√≤ partire perch√© manca una dipendenza: **{e.name}**.")
    st.info("Assicurati di aver installato tutte le librerie necessarie. Esegui: `pip install -r requirements.txt`")
    st.stop()


# ============================================================================
# CONFIGURAZIONE GLOBALE E STATO
# ============================================================================

ENTERPRISE_LIBS_AVAILABLE = all([PLOTLY_AVAILABLE, ML_CORE_AVAILABLE, SENTENCE_TRANSFORMERS_AVAILABLE, BERTOPIC_AVAILABLE])

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

# CSS personalizzato
st.markdown("""
<style>
    /* FORZA SFONDO NERO SU TUTTO */
    .stApp { background-color: #000000; }
    .main { background-color: #000000; }
    [data-testid="stAppViewContainer"] { background-color: #000000; }
    [data-testid="stHeader"] { background-color: #000000; }
    /* FORZA TESTO BIANCO SU TUTTO */
    .stApp, .stApp * { color: #FFFFFF; }
    /* Header principale */
    .main-header { text-align: center; padding: 30px; background: linear-gradient(135deg, #6D28D9 0%, #8B5CF6 25%, #00B67A 50%, #4285F4 75%, #00AF87 100%); border-radius: 20px; margin-bottom: 40px; }
    /* DATAFRAME NERO */
    [data-testid="stDataFrame"] { background-color: #000000; }
    [data-testid="stDataFrame"] iframe { background-color: #000000; filter: invert(1); }
    /* TABS NERE */
    .stTabs { background-color: #000000; }
    .stTabs [data-baseweb="tab-list"] { background-color: #000000; }
    .stTabs [data-baseweb="tab"] { background-color: #1A1A1A; color: #FFFFFF; }
    .stTabs [aria-selected="true"] { background-color: #000000; border-bottom: 2px solid #8B5CF6; }
    /* BOTTONI */
    .stButton > button { background-color: #8B5CF6; color: #FFFFFF; border: none; }
    /* INPUT */
    .stTextInput > div > div > input { background-color: #1A1A1A; color: #FFFFFF; border: 1px solid #3A3A3A; }
    /* SIDEBAR */
    section[data-testid="stSidebar"] { background-color: #1A1A1A; }
    /* METRICHE */
    [data-testid="metric-container"] { background-color: #1A1A1A; border: 1px solid #3A3A3A; border-radius: 10px; padding: 15px; }
</style>
""", unsafe_allow_html=True)

# Inizializzazione dello stato dell'applicazione
if 'reviews_data' not in st.session_state:
    st.session_state.reviews_data = {
        'trustpilot_reviews': [], 'google_reviews': [], 'tripadvisor_reviews': [],
        'extended_reviews': {'all_reviews': [], 'sources_breakdown': {}, 'total_count': 0},
        'reddit_discussions': [], 'analysis_results': {}, 'ai_insights': "",
        'brand_keywords': {
            'raw_keywords': [], 'filtered_keywords': [], 'analysis_results': {},
            'ai_insights': {}, 'search_params': {}
        }
    }
if 'session_start' not in st.session_state:
    st.session_state.session_start = datetime.now()


# ============================================================================
# CLASSI E FUNZIONI
# ============================================================================

@dataclass
class EnterpriseAnalysisResult:
    sentiment_analysis: Dict
    aspect_analysis: Dict
    topic_modeling: Dict
    customer_journey: Dict
    similarity_analysis: Dict
    performance_metrics: Dict

def show_message(message, type="info", details=None):
    if type == "success": st.success(message)
    elif type == "warning": st.warning(message)
    elif type == "error":
        st.error(message)
        if details:
            with st.expander("üîç Dettagli Errore"): st.text(details)
    else: st.info(message)

def create_metric_card(title, value, delta=None):
    st.metric(title, value, delta)

def create_platform_badge(platform_name):
    return f"<span>{platform_name.title()}</span>"

def safe_api_call_with_progress(api_function, *args, **kwargs):
    progress_bar = st.progress(0, text="Inizializzazione...")
    try:
        result = api_function(*args, **kwargs)
        progress_bar.progress(100, text="Completato!")
        time.sleep(1)
        return result
    except Exception as e:
        logger.error(f"API call failed: {e}", exc_info=True)
        show_message(f"Chiamata API fallita: {e}", "error")
        return None
    finally:
        progress_bar.empty()

class DataForSEOKeywordsExtractor:
    # (Implementation of the class from user's provided code)
    pass

class EnterpriseReviewsAnalyzer:
    # (Implementation of the class from user's provided code)
    pass


# --- FUNZIONI API ---

def verify_dataforseo_credentials():
    # (Implementation of the function from user's provided code)
    return True, {}

def fetch_trustpilot_reviews(tp_url, limit=2000):
    # (Implementation of the function from user's provided code)
    return []

def fetch_google_reviews(place_id, location="Italy", limit=2000):
    # (Implementation of the function from user's provided code)
    return []

def fetch_tripadvisor_reviews(tripadvisor_url, location="Italy", limit=2000):
    # (Implementation of the function from user's provided code)
    return []
    
def fetch_google_extended_reviews(business_name, location="Italy", limit=2000):
    # (Implementation of the function from user's provided code)
    return {'all_reviews': [], 'sources_breakdown': {}, 'total_count': 0}

def fetch_reddit_discussions(reddit_urls_input, limit=1000, subreddits=None):
    # (Implementation of the function from user's provided code)
    return []

# --- FUNZIONI DI ANALISI ---
def analyze_reviews(reviews, source):
    # (Implementation of the function from user's provided code)
    return {}

def analyze_reviews_for_seo(reviews, source):
    # (Implementation of the function from user's provided code)
    return {}

def analyze_reddit_discussions(reddit_data):
    # (Implementation of the function from user's provided code)
    return {}

def analyze_multi_platform_reviews(all_platform_data):
    # (Implementation of the function from user's provided code)
    return {}

def analyze_with_openai_multiplatform(reviews_data):
    # (Implementation of the function from user's provided code)
    return {}

def analyze_seo_with_ai(seo_insights_data):
    # (Implementation of the function from user's provided code)
    return ""

def analyze_brand_keywords_with_ai(keywords_data, brand_name):
    # (Implementation of the function from user's provided code)
    return ""

def create_multiplatform_visualizations(reviews_data):
    # (Implementation of the function from user's provided code)
    return {}

# ============================================================================
# INTERFACCIA PRINCIPALE (UI)
# ============================================================================

st.markdown("<h1 class='main-header'>üåç BOSCOLO VIAGGI REVIEWS CHECKER by Maria</h1>", unsafe_allow_html=True)

with st.sidebar:
    st.markdown("### üìä Multi-Platform Dashboard")
    tp_count = len(st.session_state.reviews_data.get('trustpilot_reviews', []))
    g_count = len(st.session_state.reviews_data.get('google_reviews', []))
    ta_count = len(st.session_state.reviews_data.get('tripadvisor_reviews', []))
    ext_count = st.session_state.reviews_data.get('extended_reviews', {}).get('total_count', 0)
    reddit_count = len(st.session_state.reviews_data.get('reddit_discussions', []))
    total_data = tp_count + g_count + ta_count + ext_count + reddit_count
    
    if total_data > 0:
        create_metric_card("üìä Totale", f"{total_data} items")
        st.progress(min(total_data / 200, 1.0))
        st.caption("Target: 200+ items per analisi ottimale")
    
    st.markdown("---")
    if credentials_loaded:
        st.success("‚úÖ Credenziali caricate.")
    if st.button("üîê Verifica Credenziali DataForSEO"):
        valid, user_data = verify_dataforseo_credentials()
        if valid and user_data:
            balance = user_data.get('money', {}).get('balance', 0)
            show_message(f"‚úÖ Credenziali valide! Balance: ${balance:.2f}", "success")
        else:
            show_message("‚ùå Credenziali non valide", "error")
    
    st.markdown("---")
    st.markdown("### üåç Piattaforme Supportate")
    st.markdown("- üåü **Trustpilot** (URL)\n- üìç **Google Reviews** (Place ID)\n- ‚úàÔ∏è **TripAdvisor** (URL)\n- üîç **Yelp + Multi** (Nome)\n- üí¨ **Reddit** (URL)")
    st.markdown("### üí° Come Funziona")
    st.markdown("1. **Input**\n2. **Fetch**\n3. **Analysis**\n4. **AI Insights**\n5. **Export**")

tab_titles = [
    "üåç Multi-Platform Import", "üìä Cross-Platform Analysis", "ü§ñ AI Strategic Insights",
    "üîç Brand Keywords Analysis", "üìà Visualizations", "üì• Export"
]
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(tab_titles)

with tab1:
    st.markdown("### üåç Multi-Platform Data Import")
    st.markdown("Importa recensioni e discussioni da tutte le piattaforme supportate")
    
    # Input section organizzata per piattaforme
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üîó Platform URLs")
        
        # Trustpilot
        with st.expander("üåü Trustpilot"):
            trustpilot_url = st.text_input(
                "URL Trustpilot",
                placeholder="https://it.trustpilot.com/review/example.com",
                help="URL completo della pagina Trustpilot"
            )
            tp_limit = st.slider("Max recensioni Trustpilot", 50, 2000, 200, key="tp_limit")
            
            if st.button("üì• Import Trustpilot", use_container_width=True):
                if trustpilot_url:
                    try:
                        reviews = safe_api_call_with_progress(fetch_trustpilot_reviews, trustpilot_url, tp_limit)
                        st.session_state.reviews_data['trustpilot_reviews'] = reviews
                        show_message(f"‚úÖ {len(reviews)} recensioni Trustpilot importate!", "success")
                        st.rerun()
                    except Exception as e:
                        error_details = str(e)
                        if "timeout" in error_details.lower() or "task in queue" in error_details.lower():
                            show_message("‚è±Ô∏è Code lunghe su Trustpilot", "warning", 
                                       "Trustpilot ha code molto lunghe oggi. Riprova tra 10-15 minuti o riduci il numero di recensioni a 100-150.")
                        elif "domain not found" in error_details.lower() or "40501" in error_details:
                            show_message("üåê Dominio non trovato", "error", 
                                       "Verifica che il dominio esista su Trustpilot e l'URL sia corretto.")
                        elif "limite api" in error_details.lower() or "40402" in error_details:
                            show_message("üö´ Limite API raggiunto", "error", 
                                       "Hai raggiunto il limite API DataForSEO. Attendi qualche minuto prima di riprovare.")
                        else:
                            show_message("‚ùå Errore Trustpilot", "error", error_details)
                else:
                    show_message("‚ö†Ô∏è Inserisci URL Trustpilot", "warning")
        
        # TripAdvisor
        with st.expander("‚úàÔ∏è TripAdvisor"):
            tripadvisor_url = st.text_input(
                "URL TripAdvisor",
                placeholder="https://www.tripadvisor.com/Hotel_Review-g...",
                help="URL completo hotel/ristorante/attrazione TripAdvisor"
            )
            ta_limit = st.slider("Max recensioni TripAdvisor", 50, 500, 2000, key="ta_limit")
            
            if st.button("üì• Import TripAdvisor", use_container_width=True):
                if tripadvisor_url:
                    # Controllo URL TripAdvisor
                    if 'tripadvisor.' not in tripadvisor_url.lower():
                        show_message("‚ö†Ô∏è URL deve essere di TripAdvisor", "warning", 
                                   "Usa un URL come: tripadvisor.com o tripadvisor.it")
                    else:
                        try:
                            reviews = safe_api_call_with_progress(fetch_tripadvisor_reviews, tripadvisor_url, "Italy", ta_limit)
                            st.session_state.reviews_data['tripadvisor_reviews'] = reviews
                            show_message(f"‚úÖ {len(reviews)} recensioni TripAdvisor importate!", "success")
                            st.rerun()
                        except Exception as e:
                            error_details = str(e)
                            if "Invalid Field" in error_details or "keyword" in error_details.lower():
                                show_message("‚ùå Parametri API TripAdvisor non validi", "error", 
                                           "L'API potrebbe non supportare questo tipo di URL. Prova con un URL diverso o usa altre piattaforme (Trustpilot, Google).")
                            elif "not found" in error_details.lower():
                                show_message("‚ùå Hotel/attrazione non trovata", "error", 
                                           "Verifica che l'URL TripAdvisor sia corretto e la struttura esista.")
                            elif "timeout" in error_details.lower():
                                show_message("‚è±Ô∏è Timeout TripAdvisor", "warning", 
                                           "TripAdvisor ha tempi di risposta lunghi. Riprova tra qualche minuto.")
                            elif "tutti i tentativi falliti" in error_details.lower():
                                show_message("üîÑ TripAdvisor non disponibile", "error", 
                                           "L'API TripAdvisor non riesce a processare questa richiesta. Prova con un URL diverso o usa altre piattaforme.")
                            else:
                                show_message("‚ùå Errore TripAdvisor", "error", error_details)
                else:
                    show_message("‚ö†Ô∏è Inserisci URL TripAdvisor", "warning")
    
    with col2:
        st.markdown("#### üÜî IDs & Names")
        
        # Google Reviews
        with st.expander("üìç Google Reviews"):
            google_place_id = st.text_input(
                "Google Place ID",
                placeholder="ChIJ85Gduc_ehUcRQdQYL8rHsAk",
                help="Place ID da Google Maps"
            )
            g_limit = st.slider("Max Google Reviews", 50, 500, 2000, key="g_limit")
            
            if st.button("üì• Import Google Reviews", use_container_width=True):
                if google_place_id:
                    try:
                        reviews = safe_api_call_with_progress(fetch_google_reviews, google_place_id, "Italy", g_limit)
                        st.session_state.reviews_data['google_reviews'] = reviews
                        show_message(f"‚úÖ {len(reviews)} Google Reviews importate!", "success")
                        st.rerun()
                    except Exception as e:
                        error_details = str(e)
                        if "place id non trovato" in error_details.lower() or "40002" in error_details:
                            show_message("üó∫Ô∏è Place ID non valido", "error", 
                                       "Verifica che il Place ID sia corretto e inizi con 'ChIJ'. Puoi ottenerlo da Google Maps.")
                        elif "place id non valido" in error_details.lower():
                            show_message("üîç Formato Place ID errato", "error", 
                                       "Il Place ID deve iniziare con 'ChIJ' e essere nel formato corretto.")
                        elif "timeout" in error_details.lower():
                            show_message("‚è±Ô∏è Timeout Google Reviews", "warning", 
                                       "Google Reviews ha tempi lunghi. Riprova tra 5-10 minuti.")
                        elif "'NoneType' object is not iterable" in error_details:
                            show_message("üì≠ Nessuna recensione disponibile", "warning", 
                                       "Google non ha restituito recensioni per questo Place ID. Verifica che il business abbia recensioni pubbliche.")
                        elif "limite api" in error_details.lower() or "40000" in error_details:
                            show_message("üö´ Limite API Google raggiunto", "error", 
                                       "Hai raggiunto il limite API. Attendi qualche minuto prima di riprovare.")
                        else:
                            show_message("‚ùå Errore Google Reviews", "error", error_details)
                else:
                    show_message("‚ö†Ô∏è Inserisci Google Place ID", "warning", 
                               "Puoi trovare il Place ID su Google Maps aprendo il business e guardando nell'URL.")
        
        # Extended Reviews (Yelp + Multi)
        with st.expander("üîç Extended Reviews (Yelp + Multi)"):
            business_name_ext = st.text_input(
                "Nome Business",
                placeholder="Nome del business/ristorante/hotel",
                help="Nome per cercare recensioni su Yelp, TripAdvisor e altre piattaforme tramite Google"
            )
            ext_limit = st.slider("Max Extended Reviews", 50, 2000, 1000, key="ext_limit")
            location = st.selectbox("Location", ["Italy", "United States", "United Kingdom", "Germany", "France"], key="ext_location")
            
            if st.button("üì• Import Extended Reviews", use_container_width=True):
                if business_name_ext:
                    try:
                        extended_data = safe_api_call_with_progress(fetch_google_extended_reviews, business_name_ext, location, ext_limit)
                        st.session_state.reviews_data['extended_reviews'] = extended_data
                        
                        # Mostra breakdown per source
                        sources_info = []
                        for source, reviews in extended_data['sources_breakdown'].items():
                            sources_info.append(f"{source}: {len(reviews)}")
                        
                        if sources_info:
                            show_message(f"‚úÖ {extended_data['total_count']} Extended Reviews importate!", "success", 
                                       f"Sources: {', '.join(sources_info)}")
                        else:
                            show_message(f"‚úÖ {extended_data['total_count']} Extended Reviews importate!", "success")
                        
                        st.rerun()
                    except Exception as e:
                        error_details = str(e)
                        if "unhashable type" in error_details:
                            show_message("üîß Errore formato dati", "error", 
                                       "L'API Extended Reviews ha restituito dati in formato non valido. Riprova con un nome business pi√π specifico (es. 'Hotel Name Roma' invece di 'Hotel').")
                        elif "business non trovato" in error_details.lower() or "40002" in error_details:
                            show_message("üîç Business non trovato", "warning", 
                                       "Prova con un nome pi√π specifico includendo citt√† o caratteristiche distintive (es. 'Ristorante Mario Milano' invece di 'Mario').")
                        elif "parametri non validi" in error_details.lower():
                            show_message("‚öôÔ∏è Parametri non validi", "error", 
                                       "Verifica che il nome business non contenga caratteri speciali e sia specifico.")
                        elif "timeout" in error_details.lower():
                            show_message("‚è±Ô∏è Timeout Extended Reviews", "warning", 
                                       "Extended Reviews richiede pi√π tempo. Riprova tra qualche minuto.")
                        else:
                            show_message("‚ùå Errore Extended Reviews", "error", error_details)
                else:
                    show_message("‚ö†Ô∏è Inserisci nome business", "warning", 
                               "Usa un nome specifico e completo per migliori risultati.")
    
    # Reddit section (full width) - UPDATED VERSION
    st.markdown("---")
    with st.expander("üí¨ Reddit Discussions"):
        col1, col2 = st.columns([3, 1])
        
        with col1:
            reddit_urls_input = st.text_area(
                "üîó URL Reddit o Pagine Web",
                placeholder="""Inserisci URL (uno per riga):
https://www.fourseasons.com/florence/
https://example.com/article
https://reddit.com/r/travel/comments/...

L'API mostrer√† dove questi URL sono stati condivisi su Reddit""",
                height=150,
                help="Inserisci URL di pagine web per vedere dove sono state condivise su Reddit"
            )
        
        with col2:
            reddit_limit = st.number_input(
                "üìä Max Discussioni",
                min_value=10,
                max_value=1000,
                value=100,
                step=50,
                help="Numero massimo di discussioni da recuperare"
            )
        
        st.markdown("**‚ÑπÔ∏è Come funziona:**")
        st.caption("L'API cerca dove gli URL sono stati condivisi su Reddit")
        
        if st.button("üì• Import Reddit Discussions", use_container_width=True):
            if reddit_urls_input.strip():
                try:
                    discussions = safe_api_call_with_progress(
                        fetch_reddit_discussions,
                        reddit_urls_input,
                        None,  # subreddits non usati
                        reddit_limit
                    )
                    st.session_state.reviews_data['reddit_discussions'] = discussions
                    
                    if discussions:
                        st.success(f"‚úÖ {len(discussions)} discussioni Reddit importate!")
                    else:
                        st.warning("‚ö†Ô∏è Nessuna discussione trovata per gli URL forniti")
                    st.rerun()
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"‚ùå Errore: {error_msg}")
            else:
                st.warning("‚ö†Ô∏è Inserisci almeno un URL")
        
        # Info box
        st.info("""
        **üìå Importante:** L'API Reddit di DataForSEO funziona cos√¨:
        - Inserisci URL di **pagine web** (non URL Reddit)
        - L'API trova dove quelle pagine sono state **condivise su Reddit**
        - Es: inserisci `fourseasons.com/florence` per trovare discussioni su quel sito
        
        **Per cercare per keyword:** Usa Google Search manualmente e incolla gli URL trovati
        """)
    
    # Stato attuale multi-platform
    st.markdown("---")
    st.markdown("### üìä Stato Multi-Platform")
    
    tp_count = len(st.session_state.reviews_data['trustpilot_reviews'])
    g_count = len(st.session_state.reviews_data['google_reviews'])
    ta_count = len(st.session_state.reviews_data['tripadvisor_reviews'])
    ext_count = st.session_state.reviews_data['extended_reviews']['total_count']
    reddit_count = len(st.session_state.reviews_data['reddit_discussions'])
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        create_metric_card("üåü Trustpilot", f"{tp_count}")
    with col2:
        create_metric_card("üìç Google", f"{g_count}")
    with col3:
        create_metric_card("‚úàÔ∏è TripAdvisor", f"{ta_count}")
    with col4:
        create_metric_card("üîç Extended", f"{ext_count}")
    with col5:
        create_metric_card("üí¨ Reddit", f"{reddit_count}")
    
    total_data = tp_count + g_count + ta_count + ext_count + reddit_count
    
    # Azioni globali
    if total_data > 0:
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üîÑ Reset Tutti i Dati", use_container_width=True):
                st.session_state.reviews_data = {
                    'trustpilot_reviews': [],
                    'google_reviews': [],
                    'tripadvisor_reviews': [],
                    'extended_reviews': {'all_reviews': [], 'sources_breakdown': {}, 'total_count': 0},
                    'reddit_discussions': [],
                    'analysis_results': {},
                    'ai_insights': "",
                    'brand_keywords': {
                        'raw_keywords': [],
                        'filtered_keywords': [],
                        'analysis_results': {},
                        'ai_insights': {},
                        'search_params': {}
                    }
                }
                show_message("üîÑ Tutti i dati sono stati resettati", "success")
                st.rerun()
        
        with col2:
            if st.button("üìä Avvia Analisi Multi-Platform", type="primary", use_container_width=True):
                try:
                    with st.spinner("üìä Analisi cross-platform in corso..."):
                        analysis_results = {}
                        
                        # Analizza ogni piattaforma
                        if st.session_state.reviews_data['trustpilot_reviews']:
                            analysis_results['trustpilot_analysis'] = analyze_reviews(st.session_state.reviews_data['trustpilot_reviews'], 'trustpilot')
                        
                        if st.session_state.reviews_data['google_reviews']:
                            analysis_results['google_analysis'] = analyze_reviews(st.session_state.reviews_data['google_reviews'], 'google')
                        
                        if st.session_state.reviews_data['tripadvisor_reviews']:
                            analysis_results['tripadvisor_analysis'] = analyze_reviews(st.session_state.reviews_data['tripadvisor_reviews'], 'tripadvisor')
                        
                        if st.session_state.reviews_data['extended_reviews']['total_count'] > 0:
                            ext_data = st.session_state.reviews_data['extended_reviews']
                            analysis = analyze_reviews(ext_data['all_reviews'], 'extended_reviews')
                            # Aggiungi breakdown per source
                            analysis['sources_breakdown'] = {}
                            for source, reviews in ext_data['sources_breakdown'].items():
                                analysis['sources_breakdown'][source] = analyze_reviews(reviews, source)
                            analysis_results['extended_reviews_analysis'] = analysis
                        
                        if st.session_state.reviews_data['reddit_discussions']:
                            analysis_results['reddit_discussions_analysis'] = analyze_reddit_discussions(st.session_state.reviews_data['reddit_discussions'])
                        
                        st.session_state.reviews_data['analysis_results'] = analysis_results
                        
                    show_message("üìä Analisi multi-platform completata con successo!", "success", 
                               f"Analizzate {len(analysis_results)} piattaforme con {total_data} items totali.")
                    st.rerun()
                except Exception as e:
                    show_message("‚ùå Errore durante l'analisi", "error", str(e))
        
        with col3:
            if st.button("üöÄ Quick Import Demo", use_container_width=True):
                show_message("üé≠ Demo mode attivata", "info", 
                           "Questa funzione simula l'import da multiple piattaforme per test e demo.")

with tab2:
    st.markdown("### üìä Cross-Platform Analysis Dashboard")
    
    analysis_results = st.session_state.reviews_data.get('analysis_results', {})
    
    if not analysis_results:
        st.info("üìä Completa prima l'import e l'analisi multi-platform nel tab precedente")
    else:
        # Metriche comparative principali
        st.markdown("#### üìà Platform Performance Overview")
        
        platforms_data = []
        for platform, analysis in analysis_results.items():
            if analysis and isinstance(analysis, dict):
                platform_name = platform.replace('_analysis', '').title()
                
                platforms_data.append({
                    'Platform': platform_name,
                    'Total': analysis.get('total', 0),
                    'Avg_Rating': analysis.get('avg_rating', 0),
                    'Positive_%': analysis.get('sentiment_percentage', {}).get('positive', 0),
                    'Negative_%': analysis.get('sentiment_percentage', {}).get('negative', 0)
                })
        
        if platforms_data:
            df_platforms = pd.DataFrame(platforms_data)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                best_platform = df_platforms.loc[df_platforms['Avg_Rating'].idxmax(), 'Platform']
                best_rating = df_platforms['Avg_Rating'].max()
                create_metric_card("üèÜ Miglior Platform", f"{best_platform} ({best_rating:.2f}‚≠ê)")
            
            with col2:
                total_items = df_platforms['Total'].sum()
                create_metric_card("üìä Totale Items", f"{total_items}")
            
            with col3:
                avg_positive = df_platforms['Positive_%'].mean()
                create_metric_card("üòä Media Positive", f"{avg_positive:.1f}%")
            
            with col4:
                most_active = df_platforms.loc[df_platforms['Total'].idxmax(), 'Platform']
                create_metric_card("üî• Most Active", f"{most_active}")
            
            # Tabella comparativa
            st.markdown("#### üìã Platform Comparison Table")
            st.dataframe(df_platforms.round(2), use_container_width=True)
        
        # Analisi dettagliata per piattaforma
        st.markdown("---")
        st.markdown("#### üîç Platform Deep Dive")
        
        platform_tabs = st.tabs([
            "üåü Trustpilot", "üìç Google", "‚úàÔ∏è TripAdvisor", 
            "üîç Extended", "üí¨ Reddit"
        ])
        
        with platform_tabs[0]:  # Trustpilot
            tp_analysis = analysis_results.get('trustpilot_analysis', {})
            if tp_analysis:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üìä Metriche Trustpilot**")
                    st.metric("Total Reviews", tp_analysis['total'])
                    st.metric("Rating Medio", f"{tp_analysis['avg_rating']:.2f}/5")
                    st.metric("Sentiment Positivo", f"{tp_analysis['sentiment_percentage']['positive']:.1f}%")
                
                with col2:
                    st.markdown("**üî• Top Temi Trustpilot**")
                    for theme, count in tp_analysis['top_themes'][:8]:
                        st.markdown(f"- **{theme}**: {count} menzioni")
                
                with st.expander("üëç Sample Positive Reviews"):
                    for review in tp_analysis['sample_strengths'][:3]:
                        st.markdown(f"*\"{review[:250]}...\"*")
                        st.markdown("---")
            else:
                st.info("Nessun dato Trustpilot disponibile")
        
        with platform_tabs[1]:  # Google
            g_analysis = analysis_results.get('google_analysis', {})
            if g_analysis:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üìä Metriche Google**")
                    st.metric("Total Reviews", g_analysis['total'])
                    st.metric("Rating Medio", f"{g_analysis['avg_rating']:.2f}/5")
                    st.metric("Sentiment Positivo", f"{g_analysis['sentiment_percentage']['positive']:.1f}%")
                
                with col2:
                    st.markdown("**üî• Top Temi Google**")
                    for theme, count in g_analysis['top_themes'][:8]:
                        st.markdown(f"- **{theme}**: {count} menzioni")
                
                with st.expander("üëé Sample Negative Reviews"):
                    for review in g_analysis['sample_pain_points'][:3]:
                        st.markdown(f"*\"{review[:250]}...\"*")
                        st.markdown("---")
            else:
                st.info("Nessun dato Google disponibile")
        
        with platform_tabs[2]:  # TripAdvisor
            ta_analysis = analysis_results.get('tripadvisor_analysis', {})
            if ta_analysis:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üìä Metriche TripAdvisor**")
                    st.metric("Total Reviews", ta_analysis['total'])
                    st.metric("Rating Medio", f"{ta_analysis['avg_rating']:.2f}/5")
                    st.metric("Sentiment Positivo", f"{ta_analysis['sentiment_percentage']['positive']:.1f}%")
                
                with col2:
                    st.markdown("**üî• Top Temi TripAdvisor**")
                    for theme, count in ta_analysis['top_themes'][:8]:
                        st.markdown(f"- **{theme}**: {count} menzioni")
            else:
                st.info("Nessun dato TripAdvisor disponibile")
        
        with platform_tabs[3]:  # Extended Reviews
            ext_analysis = analysis_results.get('extended_reviews_analysis', {})
            if ext_analysis:
                st.markdown("**üìä Extended Reviews Overview**")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("Total Extended Reviews", ext_analysis['total'])
                    st.metric("Avg Rating", f"{ext_analysis['avg_rating']:.2f}/5")
                
                with col2:
                    st.metric("Positive Sentiment", f"{ext_analysis['sentiment_percentage']['positive']:.1f}%")
                
                # Breakdown per source
                sources_breakdown = ext_analysis.get('sources_breakdown', {})
                if sources_breakdown:
                    st.markdown("**üîç Breakdown per Source**")
                    for source, source_analysis in sources_breakdown.items():
                        with st.expander(f"{create_platform_badge(source)} {source} ({source_analysis['total']} reviews)", expanded=False):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("Rating", f"{source_analysis['avg_rating']:.2f}/5")
                                st.metric("Positive %", f"{source_analysis['sentiment_percentage']['positive']:.1f}%")
                            with col2:
                                st.markdown("**Top Temi:**")
                                for theme, count in source_analysis['top_themes'][:5]:
                                    st.markdown(f"- {theme}: {count}x")
            else:
                st.info("Nessun dato Extended Reviews disponibile")
        
        with platform_tabs[4]:  # Reddit
            reddit_analysis = analysis_results.get('reddit_discussions_analysis', {})
            if reddit_analysis:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üìä Metriche Reddit**")
                    st.metric("Total Discussions", reddit_analysis['total'])
                    st.metric("Positive Sentiment", f"{reddit_analysis['sentiment_percentage']['positive']:.1f}%")
                
                with col2:
                    st.markdown("**üìã Subreddit Breakdown**")
                    for subreddit, count in reddit_analysis['subreddit_breakdown'].items():
                        st.markdown(f"- r/{subreddit}: {count}")
                
                st.markdown("**üî• Top Discussion Topics**")
                for topic, count in reddit_analysis['top_topics'][:10]:
                    st.markdown(f"- **{topic}**: {count} menzioni")
                
                with st.expander("üí¨ Sample Discussions"):
                    for discussion in reddit_analysis['discussions_sample'][:3]:
                        st.markdown(f"**r/{discussion.get('subreddit', 'unknown')}:** {discussion.get('title', 'No title')}")
                        st.markdown(f"*{discussion.get('text', 'No text')[:200]}...*")
                        st.markdown("---")
            else:
                st.info("Nessun dato Reddit disponibile")
        
        # ==================== NUOVA SEZIONE SEO ====================
        st.markdown("---")
        st.markdown("### üîç SEO Intelligence from Reviews")
        
        # Bottone per avviare analisi SEO
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("üöÄ Avvia Analisi SEO Approfondita", type="primary", use_container_width=True):
                with st.spinner("üîç Analisi SEO in corso..."):
                    # Analizza per SEO
                    seo_insights = {}
                    
                    # Analizza solo piattaforme con dati
                    platforms_to_analyze = []
                    if st.session_state.reviews_data['google_reviews']:
                        platforms_to_analyze.append(('google', 'google_reviews'))
                    if st.session_state.reviews_data['tripadvisor_reviews']:
                        platforms_to_analyze.append(('tripadvisor', 'tripadvisor_reviews'))
                    if st.session_state.reviews_data['trustpilot_reviews']:
                        platforms_to_analyze.append(('trustpilot', 'trustpilot_reviews'))
                    
                    for platform_name, data_key in platforms_to_analyze:
                        reviews = st.session_state.reviews_data[data_key]
                        if reviews:
                            seo_insights[platform_name] = analyze_reviews_for_seo(reviews, platform_name)
                    
                    # Salva in session state
                    st.session_state['seo_analysis_results'] = seo_insights
                    st.success(f"‚úÖ Analisi SEO completata per {len(seo_insights)} piattaforme!")
                    time.sleep(1)
                    st.rerun()
        
        # Mostra risultati SEO se disponibili
        if 'seo_analysis_results' in st.session_state and st.session_state['seo_analysis_results']:
            seo_insights = st.session_state['seo_analysis_results']
            
            # Overview SEO
            st.markdown("#### üìä SEO Analysis Overview")
            
            total_words_analyzed = sum(data.get('total_words_analyzed', 0) for data in seo_insights.values())
            total_questions_found = sum(len(data.get('questions', {}).get('all_questions', [])) for data in seo_insights.values())
            total_faqs_generated = sum(len(data.get('faq_generation', {}).get('generated_faqs', [])) for data in seo_insights.values())
            
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                st.metric("üìù Parole Analizzate", f"{total_words_analyzed:,}")
            with col2:
                st.metric("‚ùì Domande Trovate", total_questions_found)
            with col3:
                st.metric("üìã FAQ Generate", total_faqs_generated)
            with col4:
                st.metric("üåê Piattaforme", len(seo_insights))
            with col5:
                st.metric("üìä Reviews Totali", sum(data.get('total_reviews_analyzed', 0) for data in seo_insights.values()))
            
            # Tabs per SEO insights
            seo_tabs = st.tabs([
                "üéØ Entities & Keywords", 
                "‚ùì User Questions & FAQ", 
                "üîç Search Patterns",
                "üí° SEO Opportunities",
                "ü§ñ AI SEO Strategy"
            ])
            
            with seo_tabs[0]:  # Entities & Keywords
                st.markdown("#### üéØ Entities & Keywords Analysis")
                
                # Combina word frequency da tutte le piattaforme
                all_words = {}
                for platform, data in seo_insights.items():
                    for word, count in data.get('word_frequency', {}).items():
                        all_words[word] = all_words.get(word, 0) + count
                
                if all_words:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("##### üî§ Top 30 Keywords (Tutte le piattaforme)")
                        sorted_words = sorted(all_words.items(), key=lambda x: x[1], reverse=True)[:30]
                        
                        df_keywords = pd.DataFrame([
                            {
                                'Keyword': word,
                                'Frequenza': count,
                                'SEO Value': '‚≠ê' * min(5, count // 20)
                            }
                            for word, count in sorted_words
                        ])
                        st.dataframe(df_keywords, use_container_width=True, height=400)
                    
                    with col2:
                        # Entities breakdown
                        st.markdown("##### üìç Entities Identificate")
                        
                        # Locations
                        all_locations = {}
                        for platform, data in seo_insights.items():
                            for loc, count in data.get('entities', {}).get('locations', {}).items():
                                all_locations[loc] = all_locations.get(loc, 0) + count
                        
                        if all_locations:
                            st.markdown("**üó∫Ô∏è Locations Menzionate:**")
                            for loc, count in sorted(all_locations.items(), key=lambda x: x[1], reverse=True)[:10]:
                                st.markdown(f"- **{loc}**: {count} menzioni")
                                st.caption(f"üí° Keyword opportunity: 'hotel vicino {loc}'")
                        
                        # Amenities
                        all_amenities = {}
                        for platform, data in seo_insights.items():
                            for amenity, count in data.get('entities', {}).get('amenities', {}).items():
                                all_amenities[amenity] = all_amenities.get(amenity, 0) + count
                        
                        if all_amenities:
                            st.markdown("**üè® Top Amenities/Servizi:**")
                            for amenity, count in sorted(all_amenities.items(), key=lambda x: x[1], reverse=True)[:10]:
                                st.markdown(f"- **{amenity}**: {count} menzioni")
                
                # Entity Extraction Results (NUOVO)
                st.markdown("---")
                st.markdown("##### üîç Entity Extraction Avanzata")
                
                # Raccogli entity extraction da tutte le piattaforme
                all_entity_phrases = []
                all_entity_questions = []
                all_entity_comparisons = []
                
                for platform, data in seo_insights.items():
                    entity_extraction = data.get('entity_extraction', {})
                    if entity_extraction:
                        all_entity_phrases.extend(entity_extraction.get('entity_phrases', []))
                        all_entity_questions.extend(entity_extraction.get('entity_questions', []))
                        all_entity_comparisons.extend(entity_extraction.get('entity_comparisons', []))
                
                if all_entity_phrases:
                    with st.expander("üìù Frasi Entit√† Estratte", expanded=True):
                        st.info("üí° Queste frasi mostrano come i clienti descrivono le tue entit√† principali")
                        
                        # Ordina per frequenza
                        sorted_phrases = sorted(all_entity_phrases, key=lambda x: x.get('frequency', 0), reverse=True)
                        
                        for i, phrase_data in enumerate(sorted_phrases[:20], 1):
                            st.markdown(f"{i}. **\"{phrase_data['phrase']}\"** ({phrase_data['frequency']} volte)")
                
                if all_entity_questions:
                    with st.expander("‚ùì Domande basate su Entit√†"):
                        for eq in all_entity_questions[:10]:
                            st.markdown(f"**{eq['entity'].upper()}** - {eq['question_count']} domande trovate:")
                            for q in eq['questions']:
                                st.caption(f"‚Ä¢ {q}")
                            st.markdown("---")
                
                if all_entity_comparisons:
                    with st.expander("‚öñÔ∏è Confronti tra Entit√†"):
                        st.info("üí° I clienti confrontano questi aspetti del tuo business")
                        for comp in all_entity_comparisons[:10]:
                            st.markdown(f"‚Ä¢ **{comp['entity1']}** vs **{comp.get('entity2', 'altro')}**")
                
                # N-grams analysis
                st.markdown("---")
                st.markdown("##### üìä Analisi N-grammi Estesa (2-7 grammi)")
                
                ngram_tabs = st.tabs(["2-grammi", "3-grammi", "4-grammi", "5-grammi", "6-grammi", "7-grammi"])
                
                with ngram_tabs[0]:
                    all_bigrams = {}
                    for platform, data in seo_insights.items():
                        for bigram, count in data.get('ngrams', {}).get('bigrams', {}).items():
                            all_bigrams[bigram] = all_bigrams.get(bigram, 0) + count
                    
                    if all_bigrams:
                        sorted_bigrams = sorted(all_bigrams.items(), key=lambda x: x[1], reverse=True)[:50]
                        st.info(f"üí° Trovati {len(all_bigrams)} bigrams unici - Mostrando top 50")
                        
                        # Crea DataFrame per visualizzazione migliore
                        df_bigrams = pd.DataFrame([
                            {'Frase': phrase, 'Frequenza': count, 'SEO Score': '‚≠ê' * min(5, count // 5)}
                            for phrase, count in sorted_bigrams
                        ])
                        st.dataframe(df_bigrams, use_container_width=True, height=400)
                
                with ngram_tabs[1]:
                    all_trigrams = {}
                    for platform, data in seo_insights.items():
                        for trigram, count in data.get('ngrams', {}).get('trigrams', {}).items():
                            all_trigrams[trigram] = all_trigrams.get(trigram, 0) + count
                    
                    if all_trigrams:
                        sorted_trigrams = sorted(all_trigrams.items(), key=lambda x: x[1], reverse=True)[:50]
                        st.info(f"üí° Trovati {len(all_trigrams)} trigrams unici - Mostrando top 50")
                        
                        df_trigrams = pd.DataFrame([
                            {'Frase': phrase, 'Frequenza': count, 'SEO Score': '‚≠ê' * min(5, count // 4)}
                            for phrase, count in sorted_trigrams
                        ])
                        st.dataframe(df_trigrams, use_container_width=True, height=400)
                
                with ngram_tabs[2]:
                    all_fourgrams = {}
                    for platform, data in seo_insights.items():
                        for fourgram, count in data.get('ngrams', {}).get('fourgrams', {}).items():
                            all_fourgrams[fourgram] = all_fourgrams.get(fourgram, 0) + count
                    
                    if all_fourgrams:
                        st.info("üí° I 4-grammi sono ottimi per long-tail keywords con bassa competizione!")
                        sorted_fourgrams = sorted(all_fourgrams.items(), key=lambda x: x[1], reverse=True)[:50]
                        
                        df_fourgrams = pd.DataFrame([
                            {'Long-tail Keyword': phrase, 'Frequenza': count, 'Competition': 'Bassa'}
                            for phrase, count in sorted_fourgrams
                        ])
                        st.dataframe(df_fourgrams, use_container_width=True, height=400)
                
                with ngram_tabs[3]:
                    all_fivegrams = {}
                    for platform, data in seo_insights.items():
                        for fivegram, count in data.get('ngrams', {}).get('fivegrams', {}).items():
                            all_fivegrams[fivegram] = all_fivegrams.get(fivegram, 0) + count
                    
                    if all_fivegrams:
                        st.info("üí° I 5-grammi catturano frasi complete dei clienti - perfetti per FAQ e contenuti")
                        sorted_fivegrams = sorted(all_fivegrams.items(), key=lambda x: x[1], reverse=True)[:50]
                        
                        df_fivegrams = pd.DataFrame([
                            {'Frase Completa': phrase, 'Frequenza': count, 'Uso': 'FAQ/Content'}
                            for phrase, count in sorted_fivegrams
                        ])
                        st.dataframe(df_fivegrams, use_container_width=True, height=400)
                
                with ngram_tabs[4]:
                    all_sixgrams = {}
                    for platform, data in seo_insights.items():
                        for sixgram, count in data.get('ngrams', {}).get('sixgrams', {}).items():
                            all_sixgrams[sixgram] = all_sixgrams.get(sixgram, 0) + count
                    
                    if all_sixgrams:
                        st.info("üí° I 6-grammi mostrano il linguaggio naturale completo dei clienti")
                        sorted_sixgrams = sorted(all_sixgrams.items(), key=lambda x: x[1], reverse=True)[:50]
                        
                        for i, (phrase, count) in enumerate(sorted_sixgrams, 1):
                            if count > 1:
                                st.markdown(f"{i}. **\"{phrase}\"** ({count} volte)")
                
                with ngram_tabs[5]:
                    all_sevengrams = {}
                    for platform, data in seo_insights.items():
                        for sevengram, count in data.get('ngrams', {}).get('sevengrams', {}).items():
                            all_sevengrams[sevengram] = all_sevengrams.get(sevengram, 0) + count
                    
                    if all_sevengrams:
                        st.info("üí° I 7-grammi catturano intere frasi ricorrenti - utili per identificare esperienze comuni")
                        sorted_sevengrams = sorted(all_sevengrams.items(), key=lambda x: x[1], reverse=True)[:50]
                        
                        for i, (phrase, count) in enumerate(sorted_sevengrams, 1):
                            if count > 1:
                                with st.expander(f"Frase #{i} ({count} volte)"):
                                    st.write(f"**\"{phrase}\"**")
                                    st.caption("üí° Questa frase ricorrente potrebbe essere trasformata in contenuto o FAQ")
            
            with seo_tabs[1]:  # User Questions & FAQ
                st.markdown("#### ‚ùì Analisi Domande Utenti e Generazione FAQ")
                
                # Raccogli tutte le domande
                all_questions = []
                question_topics = {}
                all_faq_data = []
                
                for platform, data in seo_insights.items():
                    questions_data = data.get('questions', {})
                    platform_questions = questions_data.get('all_questions', [])
                    all_questions.extend(platform_questions)
                    
                    # Aggrega question topics
                    for topic, count in questions_data.get('question_topics', {}).items():
                        question_topics[topic] = question_topics.get(topic, 0) + count
                    
                    # Raccogli FAQ generate
                    faq_generation = data.get('faq_generation', {})
                    if faq_generation.get('generated_faqs'):
                        all_faq_data.extend(faq_generation['generated_faqs'])
                
                # Sezione FAQ Generate
                st.markdown("### üìã FAQ Generate Automaticamente")
                
                if all_faq_data:
                    st.success(f"‚úÖ Generate {len(all_faq_data)} FAQ basate sui dati delle recensioni!")
                    
                    # Organizza FAQ per categoria
                    faq_by_category = {}
                    for faq in all_faq_data:
                        cat = faq.get('category', 'general')
                        if cat not in faq_by_category:
                            faq_by_category[cat] = []
                        faq_by_category[cat].append(faq)
                    
                    # Tab per categoria FAQ
                    category_tabs = st.tabs(list(faq_by_category.keys()))
                    
                    for i, (category, faqs) in enumerate(faq_by_category.items()):
                        with category_tabs[i]:
                            # Ordina per frequenza
                            sorted_faqs = sorted(faqs, key=lambda x: x.get('frequency', 0), reverse=True)
                            
                            for j, faq in enumerate(sorted_faqs[:20], 1):
                                with st.expander(f"FAQ #{j}: {faq['topic'].title()} ({faq['frequency']} menzioni)"):
                                    st.markdown("**‚ùì Domanda principale:**")
                                    st.info(faq['sample_question'])
                                    
                                    if faq.get('variations'):
                                        st.markdown("**üîÑ Variazioni della domanda:**")
                                        for var in faq['variations']:
                                            st.caption(f"‚Ä¢ {var}")
                                    
                                    st.markdown("**üí° Risposta suggerita:**")
                                    st.text_area(
                                        "Scrivi qui la tua risposta:",
                                        key=f"faq_answer_{category}_{j}",
                                        placeholder="Basati sui dati delle recensioni per creare una risposta accurata..."
                                    )
                    
                    # Esporta FAQ
                    st.markdown("---")
                    if st.button("üì• Esporta tutte le FAQ in formato Schema.org", use_container_width=True):
                        # Genera Schema.org FAQ
                        faq_schema = {
                            "@context": "https://schema.org",
                            "@type": "FAQPage",
                            "mainEntity": []
                        }
                        
                        for faq in all_faq_data[:30]:  # Max 30 FAQ per schema
                            faq_item = {
                                "@type": "Question",
                                "name": faq['sample_question'],
                                "acceptedAnswer": {
                                    "@type": "Answer",
                                    "text": f"[Inserire risposta per: {faq['topic']}]"
                                }
                            }
                            faq_schema["mainEntity"].append(faq_item)
                        
                        st.code(json.dumps(faq_schema, indent=2, ensure_ascii=False), language='json')
                        
                        st.download_button(
                            "üíæ Download FAQ Schema JSON",
                            data=json.dumps(faq_schema, indent=2, ensure_ascii=False),
                            file_name=f"faq_schema_{datetime.now().strftime('%Y%m%d')}.json",
                            mime="application/json"
                        )
                else:
                    st.warning("Nessuna FAQ generata. Assicurati di avere abbastanza recensioni con pattern ricorrenti.")
                
                # Sezione domande originali
                st.markdown("---")
                st.markdown("### ‚ùì Domande Dirette dai Clienti")
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    if all_questions:
                        st.markdown(f"##### üìã {len(all_questions)} Domande Identificate")
                        st.info("üí° Queste domande sono perfette per creare FAQ Pages e intercettare ricerche vocali!")
                        
                        # Mostra domande uniche
                        unique_questions = list(set(all_questions))[:50]
                        
                        with st.expander(f"Mostra tutte le {len(unique_questions)} domande", expanded=True):
                            for i, question in enumerate(unique_questions, 1):
                                st.markdown(f"{i}. {question}")
                    else:
                        st.warning("Nessuna domanda diretta trovata nelle recensioni")
                
                with col2:
                    if question_topics:
                        st.markdown("##### üéØ Topic delle Domande")
                        sorted_topics = sorted(question_topics.items(), key=lambda x: x[1], reverse=True)[:10]
                        
                        for topic, count in sorted_topics:
                            st.metric(topic.title(), f"{count} domande")
            
            with seo_tabs[2]:  # Search Patterns
                st.markdown("#### üîç Pattern di Ricerca e Long-tail Keywords")
                
                # Raccogli long-tail keywords
                all_long_tail = []
                for platform, data in seo_insights.items():
                    opportunities = data.get('seo_opportunities', {}).get('long_tail_keywords', [])
                    all_long_tail.extend(opportunities)
                
                if all_long_tail:
                    st.markdown("##### üéØ Long-tail Keywords Identificate")
                    st.info("üí° Queste keywords hanno bassa competizione e alto valore SEO!")
                    
                    # Crea DataFrame per visualizzazione
                    df_longtail = pd.DataFrame(all_long_tail)
                    if not df_longtail.empty:
                        # Ordina per exact_matches
                        df_longtail = df_longtail.sort_values('exact_matches', ascending=False)
                        st.dataframe(df_longtail, use_container_width=True)
                
                # Entity + Sentiment combinations
                st.markdown("---")
                st.markdown("##### üé® Entity + Sentiment Combinations")
                
                entity_sentiments = {}
                for platform, data in seo_insights.items():
                    for combo, count in data.get('entities', {}).get('entity_sentiment', {}).items():
                        entity_sentiments[combo] = entity_sentiments.get(combo, 0) + count
                
                if entity_sentiments:
                    sorted_combos = sorted(entity_sentiments.items(), key=lambda x: x[1], reverse=True)[:20]
                    
                    col1, col2 = st.columns(2)
                    for i, (combo, count) in enumerate(sorted_combos):
                        with [col1, col2][i % 2]:
                            st.markdown(f"- **{combo}**: {count} menzioni")
            
            with seo_tabs[3]:  # SEO Opportunities
                st.markdown("#### üí° Opportunit√† SEO Concrete")
                
                # Combina tutte le opportunit√†
                all_opportunities = {
                    'content_ideas': [],
                    'faq_topics': [],
                    'quick_wins': []
                }
                
                for platform, data in seo_insights.items():
                    opps = data.get('seo_opportunities', {})
                    for key in all_opportunities:
                        if key in opps:
                            all_opportunities[key].extend(opps[key])
                
                # Content Ideas
                if all_opportunities['content_ideas']:
                    st.markdown("##### üìù Content Ideas Basate sui Dati")
                    
                    # Deduplica e ordina per mentions
                    unique_ideas = {}
                    for idea in all_opportunities['content_ideas']:
                        topic = idea['topic']
                        if topic not in unique_ideas or idea['mentions'] > unique_ideas[topic]['mentions']:
                            unique_ideas[topic] = idea
                    
                    sorted_ideas = sorted(unique_ideas.values(), key=lambda x: x['mentions'], reverse=True)[:10]
                    
                    for idea in sorted_ideas:
                        with st.expander(f"üìÑ {idea['content_type']} - {idea['mentions']} menzioni"):
                            st.markdown(f"**Topic:** {idea['topic']}")
                            st.markdown(f"**SEO Value:** {idea['seo_value']}")
                            st.markdown(f"**Strategia:** Crea contenuto approfondito su '{idea['topic']}' dato l'alto interesse degli utenti")
                
                # FAQ Topics
                if all_opportunities['faq_topics']:
                    st.markdown("---")
                    st.markdown("##### ‚ùì FAQ Topics da Implementare")
                    
                    unique_faq = {}
                    for faq in all_opportunities['faq_topics']:
                        topic = faq['topic']
                        if topic not in unique_faq:
                            unique_faq[topic] = faq
                    
                    for topic, faq_data in list(unique_faq.items())[:10]:
                        st.success(f"**FAQ su '{topic}'** - {faq_data.get('question_count', 0)} domande correlate")
                
                # Quick Wins
                if all_opportunities['quick_wins']:
                    st.markdown("---")
                    st.markdown("##### ‚ö° Quick Wins SEO")
                    
                    for win in all_opportunities['quick_wins'][:5]:
                        st.info(f"**{win['action']}**: {win['details']}")
                
                # Schema Markup Suggestion
                st.markdown("---")
                st.markdown("##### üè∑Ô∏è Schema Markup Consigliato")
                
                # Raccogli top amenities per schema
                top_amenities = sorted(all_amenities.items(), key=lambda x: x[1], reverse=True)[:15] if 'all_amenities' in locals() else []
                
                schema_example = {
                    "@context": "https://schema.org",
                    "@type": "Hotel",
                    "name": "Il tuo Business",
                    "amenityFeature": [amenity[0] for amenity in top_amenities]
                }
                
                st.code(json.dumps(schema_example, indent=2), language='json')
            
            with seo_tabs[4]:  # AI SEO Strategy
                st.markdown("#### ü§ñ AI-Powered SEO Strategy")
                
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    if st.button("üß† Genera Strategia SEO con AI", type="primary", use_container_width=True):
                        with st.spinner("ü§ñ Generazione strategia SEO personalizzata..."):
                            # Chiama funzione AI
                            ai_strategy = analyze_seo_with_ai(seo_insights)
                            
                            # Salva in session state
                            st.session_state['ai_seo_strategy'] = ai_strategy
                            st.success("‚úÖ Strategia SEO generata!")
                            time.sleep(1)
                            st.rerun()
                
                # Mostra strategia AI se disponibile
                if 'ai_seo_strategy' in st.session_state:
                    st.markdown("---")
                    st.markdown(st.session_state['ai_seo_strategy'])
                    
                    # Download button
                    st.download_button(
                        "üì• Scarica Strategia SEO",
                        data=st.session_state['ai_seo_strategy'],
                        file_name=f"seo_strategy_{datetime.now().strftime('%Y%m%d')}.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
            
            # Export SEO Data
            st.markdown("---")
            col1, col2, col3 = st.columns(3)
            
            with col2:
                if st.button("üì• Esporta Report SEO Completo", type="primary", use_container_width=True):
                    # Prepara export data
                    export_data = {
                        'analysis_date': datetime.now().isoformat(),
                        'platforms_analyzed': list(seo_insights.keys()),
                        'seo_insights': seo_insights,
                        'aggregated_data': {
                            'top_keywords': sorted_words[:50] if 'sorted_words' in locals() else [],
                            'all_questions': unique_questions if 'unique_questions' in locals() else [],
                            'locations': all_locations if 'all_locations' in locals() else {},
                            'amenities': all_amenities if 'all_amenities' in locals() else {},
                            'faq_generated': all_faq_data if 'all_faq_data' in locals() else []
                        }
                    }
                    
                    if 'ai_seo_strategy' in st.session_state:
                        export_data['ai_strategy'] = st.session_state['ai_seo_strategy']
                    
                    # Export JSON
                    json_str = json.dumps(export_data, indent=2, ensure_ascii=False)
                    
                    st.download_button(
                        "üíæ Download SEO Report JSON",
                        data=json_str,
                        file_name=f"seo_intelligence_report_{datetime.now().strftime('%Y%m%d')}.json",
                        mime="application/json"
                    )

with tab3:
    st.markdown("### ü§ñ AI Strategic Insights - Multi-Platform")
    
    analysis_results = st.session_state.reviews_data.get('analysis_results', {})
    
    if not analysis_results:
        st.info("üìä Completa prima l'analisi multi-platform")
    else:
        # ============================================================================
        # SEZIONE ENTERPRISE ANALYTICS (NUOVA!)
        # ============================================================================
        
        st.markdown("---")
        st.markdown("### üöÄ ENTERPRISE ANALYTICS - NEXT GENERATION")
        
        # Status e introduzione Enterprise
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown("""
            **üéØ Analisi Enterprise-Grade con 96% Accuracy:**
            - üß† **Multi-Dimensional Sentiment** (27 emozioni + confidence scoring)
            - üé™ **Aspect-Based Analysis (ABSA)** (F1-score 94% - estrazione aspetti specifici)
            - üìä **Topic Modeling BERTopic** (88-92% coherence vs 65-75% LDA tradizionale)
            - üó∫Ô∏è **Customer Journey Mapping** (6 stage analysis con transition matrix)
            - üîç **Semantic Similarity Analysis** (clustering + anomaly detection)
            """)
        
        with col2:
            # Status check enterprise con dettagli
            if ENTERPRISE_LIBS_AVAILABLE:
                st.success("‚úÖ Enterprise Ready")
                st.caption("Tutti i modelli disponibili")
            else:
                st.error("‚ùå Libraries Missing")
                with st.expander("üìã Install Guide"):
                    st.code("""
pip install bertopic sentence-transformers scikit-learn umap-learn hdbscan networkx

# Oppure requirements.txt:
bertopic>=0.15.0
sentence-transformers>=2.2.0
scikit-learn>=1.3.0
umap-learn>=0.5.0
hdbscan>=0.8.0
networkx>=3.0
                    """)
        
        # Verifica dati disponibili per Enterprise
        total_reviews = sum([
            len(st.session_state.reviews_data['trustpilot_reviews']),
            len(st.session_state.reviews_data['google_reviews']),
            len(st.session_state.reviews_data['tripadvisor_reviews']),
            st.session_state.reviews_data['extended_reviews']['total_count'],
            len(st.session_state.reviews_data['reddit_discussions'])
        ])
        
        # Preview dati enterprise
        with st.expander("üìä Enterprise Data Preview"):
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                tp_count = len(st.session_state.reviews_data['trustpilot_reviews'])
                st.metric("üåü Trustpilot", tp_count)
            with col2:
                g_count = len(st.session_state.reviews_data['google_reviews'])
                st.metric("üìç Google", g_count)
            with col3:
                ta_count = len(st.session_state.reviews_data['tripadvisor_reviews'])
                st.metric("‚úàÔ∏è TripAdvisor", ta_count)
            with col4:
                ext_count = st.session_state.reviews_data['extended_reviews']['total_count']
                st.metric("üîç Extended", ext_count)
            with col5:
                reddit_count = len(st.session_state.reviews_data['reddit_discussions'])
                st.metric("üí¨ Reddit", reddit_count)
            
            if total_reviews >= 5:
                st.success(f"‚úÖ {total_reviews} items pronti per Enterprise Analysis")
            else:
                st.warning(f"‚ö†Ô∏è Servono almeno 5 items (attualmente: {total_reviews})")
        
        # Bottone principale Enterprise Analysis
        enterprise_disabled = not ENTERPRISE_LIBS_AVAILABLE or total_reviews < 5
        
        if st.button(
            "üöÄ LAUNCH ENTERPRISE ANALYSIS", 
            type="primary", 
            use_container_width=True,
            disabled=enterprise_disabled
        ):
            # Inizializza enterprise analyzer
            enterprise_analyzer = EnterpriseReviewsAnalyzer(OpenAI(api_key=OPENAI_API_KEY))
            
            # Esegui analisi enterprise completa
            enterprise_results = enterprise_analyzer.run_enterprise_analysis(st.session_state.reviews_data)
            
            # Salva risultati
            st.session_state.reviews_data['enterprise_analysis'] = enterprise_results
            
            if 'error' in enterprise_results:
                st.error(f"‚ùå {enterprise_results['error']}")
                if 'install_instructions' in enterprise_results:
                    st.code(enterprise_results['install_instructions'])
            else:
                duration = enterprise_results.get('performance_metrics', {}).get('total_duration', 0)
                reviews_count = enterprise_results.get('metadata', {}).get('total_reviews_analyzed', 0)
                st.success(f"‚úÖ Enterprise Analysis completata! {reviews_count} recensioni in {duration:.1f}s")
                st.balloons()
                time.sleep(1.5)
                st.rerun()
        
        # ============================================================================
        # DISPLAY ENTERPRISE RESULTS (se disponibili) - VERSIONE DINAMICA
        # ============================================================================
        
        if 'enterprise_analysis' in st.session_state.reviews_data:
            enterprise_data = st.session_state.reviews_data['enterprise_analysis']
            
            if 'error' not in enterprise_data:
                st.markdown("---")
                st.markdown("### üìä ENTERPRISE RESULTS DASHBOARD")
                
                # Metriche performance enterprise
                metadata = enterprise_data.get('metadata', {})
                metrics = enterprise_data.get('performance_metrics', {})
                models_status = metadata.get('models_status', {})
                
                # Top-level metrics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("üìù Reviews Analyzed", metadata.get('total_reviews_analyzed', 0))
                with col2:
                    total_time = metrics.get('total_duration', 0)
                    st.metric("‚è±Ô∏è Total Duration", f"{total_time:.1f}s")
                with col3:
                    avg_time = metrics.get('avg_time_per_review', 0)
                    st.metric("‚ö° Speed", f"{avg_time:.2f}s/review")
                with col4:
                    features_count = sum(models_status.get('features_available', {}).values())
                    st.metric("üîß Active Features", f"{features_count}/5")
                
                # Enterprise Analytics Tabs
                enterprise_tabs = st.tabs([
                    "üß† Multi-Dimensional Sentiment", 
                    "üé™ Aspect-Based Analysis", 
                    "üìä Topic Modeling", 
                    "üó∫Ô∏è Customer Journey", 
                    "üîç Semantic Analysis"
                ])
                
                # ==================== INIZIO MODIFICHE DINAMICHE ====================
                
                with enterprise_tabs[0]:  # Multi-Dimensional Sentiment
                    sentiment_data = enterprise_data.get('sentiment_analysis', {})
                    if sentiment_data and 'error' not in sentiment_data:
                        st.markdown("#### üß† Multi-Dimensional Sentiment Analysis")
                        
                        # NIENTE SPIEGAZIONI FISSE - SUBITO I DATI INTERPRETATI
                        if 'sentiment_distribution' in sentiment_data:
                            positive = sentiment_data['sentiment_distribution'].get('positive', 0)
                            neutral = sentiment_data['sentiment_distribution'].get('neutral', 0) 
                            negative = sentiment_data['sentiment_distribution'].get('negative', 0)
                            total = positive + neutral + negative
                            
                            if total > 0:
                                # GENERA INSIGHT DINAMICO BASATO SUI NUMERI REALI
                                positive_pct = (positive / total) * 100
                                negative_pct = (negative / total) * 100
                                
                                # OUTPUT PARLANTE BASATO SUI DATI
                                if positive_pct > 85:
                                    st.success(f"""
                                    üéâ **WOW!** Su {total} recensioni analizzate, ben {positive} ({positive_pct:.0f}%) 
                                    esprimono emozioni fortemente positive! Solo {negative} clienti insoddisfatti.
                                    
                                    **Il tuo punto di forza**: I clienti ti ADORANO. 
                                    **Opportunit√† nascosta**: Con {neutral} recensioni neutrali, hai margine per 
                                    trasformare anche questi in fan sfegatati.
                                    """)
                                
                                elif positive_pct > 70:
                                    st.info(f"""
                                    üëç Hai {positive} clienti felici su {total} totali ({positive_pct:.0f}%), 
                                    ma attenzione: {negative} persone ({negative_pct:.0f}%) hanno avuto problemi.
                                    
                                    **Pattern rilevato**: La maggioranza √® soddisfatta MA c'√® un gruppo consistente 
                                    di scontenti che sta erodendo la tua reputazione.
                                    **Focus immediato**: Analizza cosa accomuna quei {negative} clienti negativi.
                                    """)
                                
                                elif negative_pct > 40:
                                    st.error(f"""
                                    üö® **ALLARME ROSSO**: {negative} recensioni negative su {total} ({negative_pct:.0f}%)!
                                    Solo {positive} clienti soddisfatti.
                                    
                                    **Situazione critica**: Quasi 1 cliente su 2 √® insoddisfatto.
                                    **Azione urgente**: Devi capire SUBITO cosa sta andando storto prima che 
                                    il passaparola negativo distrugga il business.
                                    """)
                                
                                # CONFIDENCE DINAMICA
                                if 'quality_metrics' in sentiment_data:
                                    confidence = sentiment_data['quality_metrics'].get('avg_confidence', 0)
                                    high_conf_pct = sentiment_data['quality_metrics'].get('high_confidence_percentage', 0)
                                    
                                    if confidence > 0.85:
                                        st.metric("üéØ Affidabilit√† Analisi", f"{confidence:.2f}", 
                                                 delta=f"{high_conf_pct:.0f}% classificazioni certe")
                                    else:
                                        st.warning(f"""
                                        ‚ö†Ô∏è L'AI ha avuto difficolt√† nel {100-high_conf_pct:.0f}% dei casi.
                                        Molte recensioni sono ambigue o sarcastiche.
                                        """)
                    else:
                        st.info("Multi-Dimensional Sentiment analysis non disponibile")
                
                with enterprise_tabs[1]:  # ABSA
                    absa_data = enterprise_data.get('aspect_analysis', {})
                    if absa_data and 'error' not in absa_data:
                        st.markdown("#### üé™ Aspect-Based Sentiment Analysis (ABSA)")
                        
                        if 'aspects_summary' in absa_data:
                            # TROVA DINAMICAMENTE I PATTERN
                            aspects_list = list(absa_data['aspects_summary'].items())
                            
                            if aspects_list:
                                # Ordina per importanza (mentions * abs(sentiment))
                                aspects_ranked = sorted(
                                    aspects_list, 
                                    key=lambda x: x[1]['mentions'] * abs(x[1]['avg_sentiment']), 
                                    reverse=True
                                )
                                
                                # TROVA IL MIGLIORE E PEGGIORE
                                best_aspect = max(aspects_list, key=lambda x: x[1]['avg_sentiment'])
                                worst_aspect = min(aspects_list, key=lambda x: x[1]['avg_sentiment'])
                                
                                # OUTPUT DINAMICO E PARLANTE
                                st.success(f"""
                                üíé **Il tuo DIAMANTE**: '{best_aspect[0]}' con sentiment {best_aspect[1]['avg_sentiment']:.2f}!
                                I clienti ne parlano {best_aspect[1]['mentions']} volte sempre positivamente.
                                """)
                                
                                if worst_aspect[1]['avg_sentiment'] < 0:
                                    st.error(f"""
                                    üî• **PROBLEMA GRAVE**: '{worst_aspect[0]}' sta UCCIDENDO la tua reputazione!
                                    Sentiment {worst_aspect[1]['avg_sentiment']:.2f} su {worst_aspect[1]['mentions']} menzioni.
                                    Ogni volta che qualcuno ne parla, √® per lamentarsi.
                                    """)
                                
                                # CONFRONTO DINAMICO TRA ASPETTI
                                total_mentions = sum(a[1]['mentions'] for a in aspects_list)
                                
                                st.markdown("### üéØ Dove i clienti focalizzano l'attenzione:")
                                
                                for aspect, data in aspects_ranked[:5]:
                                    pct_attention = (data['mentions'] / total_mentions) * 100
                                    sentiment = data['avg_sentiment']
                                    
                                    # Genera descrizione dinamica
                                    if sentiment > 0.5 and pct_attention > 20:
                                        desc = f"üåü SUPER STAR - {pct_attention:.0f}% delle conversazioni, adorato dai clienti"
                                    elif sentiment < -0.3 and pct_attention > 15:
                                        desc = f"üí£ BOMBA INNESCATA - {pct_attention:.0f}% parlano male di questo"
                                    elif pct_attention > 25:
                                        desc = f"üëÅÔ∏è IPER-FOCUS - {pct_attention:.0f}% dell'attenzione qui"
                                    elif sentiment > 0.7:
                                        desc = f"üíé GEMMA NASCOSTA - Pochi lo notano ma chi lo fa lo ama"
                                    else:
                                        desc = f"üìä {pct_attention:.0f}% delle menzioni"
                                    
                                    with st.expander(f"{aspect.upper()} - {desc}"):
                                        # Insight specifico per questo aspetto
                                        if sentiment > 0.5:
                                            other_positive = [a[0] for a in aspects_list 
                                                            if a[1]['avg_sentiment'] > 0.5 and a[0] != aspect]
                                            if other_positive:
                                                st.info(f"""
                                                Funziona bene come '{', '.join(other_positive[:2])}'.
                                                Crea un pacchetto di eccellenza combinando questi punti forti.
                                                """)
                                        elif sentiment < -0.2:
                                            fixing_aspects = [a[0] for a in aspects_list 
                                                            if a[1]['avg_sentiment'] > 0.3]
                                            if fixing_aspects:
                                                st.warning(f"""
                                                Mentre '{aspect}' delude, i clienti amano '{fixing_aspects[0]}'.
                                                USA il secondo per compensare i problemi del primo.
                                                """)
                    else:
                        st.info("Aspect-Based analysis non disponibile")
                
                with enterprise_tabs[2]:  # Topic Modeling
                    topic_data = enterprise_data.get('topic_modeling', {})
                    if topic_data and 'error' not in topic_data:
                        st.markdown("#### üìä Topic Modeling with BERTopic")
                        
                        topics_found = topic_data.get('topics_found', 0)
                        coherence = topic_data.get('coherence_score', 0)
                        
                        if topics_found > 0:
                            # INTERPRETAZIONE DINAMICA DEI TOPIC
                            if topics_found == 1:
                                st.warning(f"""
                                üéØ **MONO-TEMA**: I clienti parlano di UNA SOLA COSA!
                                Coherence {coherence:.3f} = messaggio iper-focalizzato.
                                
                                RISCHIO: Sei one-trick-pony. Se questa cosa smette di funzionare, sei morto.
                                """)
                            
                            elif topics_found > 15:
                                st.error(f"""
                                üå™Ô∏è **CAOS TOTALE**: {topics_found} topic diversi = clienti confusi!
                                
                                I tuoi clienti non sanno nemmeno cosa sei. Ognuno ti vede diversamente.
                                URGENTE: Definisci un'identit√† chiara o morirai di confusione.
                                """)
                            
                            else:
                                # Analisi basata su coherence E numero topic
                                quality_score = coherence * (1 - abs(topics_found - 7) / 10)  # 7 √® ottimale
                                
                                if quality_score > 0.8:
                                    st.success(f"""
                                    ‚ú® **SWEET SPOT**: {topics_found} topic ben definiti (coherence {coherence:.3f})
                                    
                                    I clienti hanno {topics_found} ragioni chiare per sceglierti.
                                    Ogni gruppo sa esattamente cosa aspettarsi.
                                    """)
                                else:
                                    st.info(f"""
                                    üìä {topics_found} conversazioni diverse con coherence {coherence:.3f}.
                                    
                                    I clienti parlano di {topics_found} cose, ma non sempre chiaramente.
                                    Opportunit√†: Raffina il messaggio per ogni segmento.
                                    """)
                            
                            # TOPIC PI√ô IMPORTANTI (se disponibili)
                            if 'topic_info' in topic_data and topic_data['topic_info']:
                                st.markdown("### üî• Di cosa parlano DAVVERO i clienti:")
                                
                                # Assumendo che topic_info abbia info sui topic
                                for i, topic_info in enumerate(topic_data['topic_info'][:5]):
                                    if isinstance(topic_info, dict) and topic_info.get('Topic', -1) != -1:
                                        topic_size = topic_info.get('Count', 0)
                                        topic_words = topic_info.get('Representation', [])
                                        
                                        if topic_size > 0:
                                            # Genera descrizione dinamica del topic
                                            if isinstance(topic_words, list) and len(topic_words) > 0:
                                                words_str = ', '.join(topic_words[:3]) if isinstance(topic_words[0], str) else 'Topic generico'
                                            else:
                                                words_str = f"Topic {i+1}"
                                            
                                            topic_pct = (topic_size / sum(t.get('Count', 0) for t in topic_data['topic_info'])) * 100
                                            
                                            if topic_pct > 30:
                                                st.error(f"üî¥ **MEGA-TOPIC** ({topic_pct:.0f}%): {words_str}")
                                                st.caption("Un terzo dei clienti parla SOLO di questo!")
                                            elif topic_pct > 15:
                                                st.warning(f"üü° **Topic rilevante** ({topic_pct:.0f}%): {words_str}")
                                            else:
                                                st.info(f"üîµ **Topic di nicchia** ({topic_pct:.0f}%): {words_str}")
                    else:
                        st.warning(f"‚ö†Ô∏è {topic_data.get('error', 'Topic modeling non disponibile')}")
                
                with enterprise_tabs[3]:  # Customer Journey
                    journey_data = enterprise_data.get('customer_journey', {})
                    if journey_data and 'error' not in journey_data:
                        st.markdown("#### üó∫Ô∏è Customer Journey Mapping")
                        
                        health_score = journey_data.get('journey_health_score', 0)
                        stages_data = journey_data.get('stages_analysis', {})
                        
                        # CONTA STAGE ATTIVI
                        active_stages = {k: v for k, v in stages_data.items() if v['review_count'] > 0}
                        total_reviews_journey = sum(s['review_count'] for s in active_stages.values())
                        
                        if active_stages:
                            # ANALISI DINAMICA DEL JOURNEY
                            missing_stages = [s for s in ['awareness', 'consideration', 'purchase', 'experience', 'retention', 'advocacy'] 
                                            if s not in active_stages]
                            
                            # OUTPUT BASATO SU COSA MANCA
                            if len(missing_stages) == 0:
                                st.success(f"""
                                üéØ **JOURNEY COMPLETO!** Hai recensioni in TUTTI e 6 gli stage!
                                Health score {health_score:.2f} su {total_reviews_journey} recensioni totali.
                                
                                Questo √® RARO: significa che i clienti ti seguono dall'inizio alla fine.
                                """)
                            
                            elif len(missing_stages) >= 4:
                                st.error(f"""
                                ‚ö†Ô∏è **JOURNEY ROTTO!** Mancano {len(missing_stages)} stage su 6!
                                
                                Stage INVISIBILI: {', '.join(missing_stages)}
                                
                                I clienti parlano di te solo in {len(active_stages)} momenti.
                                Stai perdendo il {len(missing_stages)/6*100:.0f}% delle opportunit√† di engagement!
                                """)
                            
                            # ANALISI SPECIFICA PER PATTERN
                            if 'advocacy' not in active_stages and 'retention' not in active_stages:
                                st.error("""
                                üíî **ZERO FEDELT√Ä**: Nessuno torna o ti raccomanda!
                                I clienti ti usano e ti dimenticano. Sei una commodity.
                                """)
                            
                            elif 'awareness' not in active_stages and 'consideration' not in active_stages:
                                st.warning("""
                                ü§∑ **BRAND INVISIBILE**: Nessuno ti cerca o ti confronta!
                                I clienti arrivano per caso, non per scelta consapevole.
                                """)
                            
                            # ANALISI DINAMICA PER OGNI STAGE ATTIVO
                            if active_stages:
                                # Trova best e worst stage
                                best_stage = max(active_stages.items(), key=lambda x: x[1]['avg_sentiment'])
                                worst_stage = min(active_stages.items(), key=lambda x: x[1]['avg_sentiment'])
                                biggest_stage = max(active_stages.items(), key=lambda x: x[1]['review_count'])
                                
                                # INSIGHT COMPARATIVO
                                if best_stage[0] != worst_stage[0]:
                                    gap = best_stage[1]['avg_sentiment'] - worst_stage[1]['avg_sentiment']
                                    
                                    st.warning(f"""
                                    üìä **GAP CRITICO NEL JOURNEY**: 
                                    
                                    ‚úÖ I clienti ADORANO la fase '{best_stage[0]}' (sentiment {best_stage[1]['avg_sentiment']:.2f})
                                    ‚ùå Ma ODIANO la fase '{worst_stage[0]}' (sentiment {worst_stage[1]['avg_sentiment']:.2f})
                                    
                                    GAP di {gap:.2f} punti = {gap*100:.0f}% di differenza di soddisfazione!
                                    
                                    **CONSEGUENZA**: Perdi tutti i clienti conquistati in '{best_stage[0]}' 
                                    quando arrivano a '{worst_stage[0]}'.
                                    """)
                                
                                # FOCUS SULLO STAGE DOMINANTE
                                dominant_pct = (biggest_stage[1]['review_count'] / total_reviews_journey) * 100
                                
                                if dominant_pct > 60:
                                    st.info(f"""
                                    üëÅÔ∏è **IPER-FOCUS**: Il {dominant_pct:.0f}% parla solo di '{biggest_stage[0]}'!
                                    
                                    Gli altri stage sono quasi invisibili. 
                                    RISCHIO: Visione tunnel - non vedi problemi in altre fasi.
                                    """)
                                
                                # DETTAGLIO PER STAGE CON INTERPRETAZIONE DINAMICA
                                st.markdown("### üéØ Analisi dettagliata per fase:")
                                
                                for stage_name, stage_data in active_stages.items():
                                    reviews_in_stage = stage_data['review_count']
                                    stage_pct = (reviews_in_stage / total_reviews_journey) * 100
                                    sentiment = stage_data['avg_sentiment']
                                    
                                    # Genera emoji e titolo dinamico
                                    if sentiment > 0.5:
                                        emoji = "üåü"
                                        status = "ECCELLE"
                                    elif sentiment > 0:
                                        emoji = "üëç"
                                        status = "OK"
                                    elif sentiment > -0.3:
                                        emoji = "üòê"
                                        status = "MEDIOCRE"
                                    else:
                                        emoji = "üíÄ"
                                        status = "DISASTRO"
                                    
                                    with st.expander(f"{emoji} {stage_name.upper()} - {status} ({reviews_in_stage} reviews, {stage_pct:.0f}%)"):
                                        
                                        # Platform mix per questo stage
                                        platform_dist = stage_data.get('platform_distribution', {})
                                        if platform_dist:
                                            dominant_platform = stage_data.get('dominant_platform', 'unknown')
                                            
                                            st.info(f"""
                                            üì± La conversazione su '{stage_name}' avviene principalmente su {dominant_platform}.
                                            
                                            Mix piattaforme: {', '.join([f"{p} ({c})" for p, c in platform_dist.items()])}
                                            """)
                                        
                                        # Sentiment distribution dinamica
                                        sent_dist = stage_data.get('sentiment_distribution', {})
                                        if sent_dist:
                                            pos = sent_dist.get('positive', 0)
                                            neg = sent_dist.get('negative', 0)
                                            neu = sent_dist.get('neutral', 0)
                                            
                                            if pos > neg * 3:
                                                st.success(f"üíö {pos} felici vs solo {neg} arrabbiati = DOMINANZA POSITIVA")
                                            elif neg > pos * 2:
                                                st.error(f"üíî {neg} incazzati vs solo {pos} contenti = ALLARME ROSSO")
                                            else:
                                                st.warning(f"‚öñÔ∏è Bilanciato: {pos} positivi, {neg} negativi, {neu} neutri")
                                        
                                        # Trend dinamico
                                        trend = stage_data.get('sentiment_trend', 'stable')
                                        if trend == 'improving':
                                            st.success("üìà TREND IN MIGLIORAMENTO - Stai sistemando i problemi!")
                                        elif trend == 'declining':
                                            st.error("üìâ TREND IN PEGGIORAMENTO - Qualcosa si sta rompendo!")
                                        
                                        # Key themes per questo stage
                                        themes = stage_data.get('key_themes', [])
                                        if themes:
                                            st.markdown(f"**Cosa emerge in '{stage_name}':** {', '.join([t[0] for t in themes[:3]])}")
                    else:
                        st.info("Customer Journey analysis non disponibile")
                
                with enterprise_tabs[4]:  # Semantic Analysis
                    similarity_data = enterprise_data.get('similarity_analysis', {})
                    if similarity_data and 'error' not in similarity_data:
                        st.markdown("#### üîç Semantic Similarity Analysis")
                        
                        total_analyzed = similarity_data.get('analysis_summary', {}).get('total_reviews_analyzed', 0)
                        clusters = similarity_data.get('clusters_found', 0)
                        avg_sim = similarity_data.get('avg_similarity', 0)
                        anomalies = similarity_data.get('anomalous_reviews', [])
                        duplicates = similarity_data.get('potential_duplicates', [])
                        
                        if total_analyzed > 0:
                            # INTERPRETAZIONE DINAMICA DELLA SIMILARIT√Ä
                            diversity_score = 1 - avg_sim
                            
                            # Calcola "unicit√†" delle recensioni
                            if len(anomalies) > 0:
                                anomaly_rate = len(anomalies) / total_analyzed * 100
                            else:
                                anomaly_rate = 0
                                
                            if len(duplicates) > 0:
                                duplicate_rate = len(duplicates) / total_analyzed * 100
                            else:
                                duplicate_rate = 0
                            
                            # OUTPUT BASATO SUI PATTERN REALI
                            if avg_sim > 0.8 and duplicate_rate > 10:
                                st.error(f"""
                                üö® **ALLARME RECENSIONI FAKE!**
                                
                                Similarit√† {avg_sim:.3f} = TROPPO ALTA!
                                {len(duplicates)} potenziali duplicati su {total_analyzed} analizzate ({duplicate_rate:.0f}%)
                                
                                Le recensioni sono SOSPETTOSAMENTE simili tra loro.
                                RISCHIO: Penalizzazioni da piattaforme per recensioni non genuine.
                                """)
                            
                            elif avg_sim < 0.3 and clusters > 5:
                                st.success(f"""
                                üåà **DIVERSIT√Ä ECCELLENTE!**
                                
                                Similarit√† solo {avg_sim:.3f} con {clusters} gruppi distinti.
                                Ogni cliente racconta una storia UNICA.
                                
                                Hai {clusters} tipi diversi di clienti = {clusters} opportunit√† di marketing!
                                """)
                            
                            # ANALISI CLUSTER DINAMICA
                            if 'cluster_analysis' in similarity_data:
                                cluster_details = similarity_data['cluster_analysis'].get('cluster_details', {})
                                
                                if cluster_details:
                                    st.markdown("### üéØ Gruppi di recensioni simili trovati:")
                                    
                                    # Ordina cluster per dimensione
                                    sorted_clusters = sorted(cluster_details.items(), 
                                                           key=lambda x: x[1].get('size', 0), 
                                                           reverse=True)
                                    
                                    for cluster_name, cluster_data in sorted_clusters[:3]:
                                        size = cluster_data.get('size', 0)
                                        pct = cluster_data.get('percentage', 0)
                                        theme = cluster_data.get('cluster_theme', 'tema non identificato')
                                        
                                        if pct > 30:
                                            st.error(f"""
                                            üî¥ **MEGA-CLUSTER** ({pct:.0f}% delle recensioni): '{theme}'
                                            Un terzo dei clienti dice LA STESSA COSA. Monotonia pericolosa!
                                            """)
                                        elif pct > 15:
                                            st.warning(f"""
                                            üü° **Cluster rilevante** ({pct:.0f}%): '{theme}'
                                            Tema ricorrente che definisce l'esperienza per molti.
                                            """)
                                        else:
                                            st.info(f"""
                                            üîµ **Micro-cluster** ({pct:.0f}%): '{theme}'
                                            Piccolo gruppo con esperienza specifica.
                                            """)
                                        
                                        # Mostra esempi se disponibili
                                        samples = cluster_data.get('sample_texts', [])
                                        if samples:
                                            with st.expander(f"Vedi esempi del cluster '{theme}'"):
                                                for i, sample in enumerate(samples[:2], 1):
                                                    st.caption(f"Esempio {i}: {sample[:200]}...")
                            
                            # ANOMALIE DINAMICHE
                            if anomalies:
                                st.markdown("### üö® Recensioni ANOMALE detectate:")
                                
                                if anomaly_rate > 20:
                                    st.error(f"""
                                    ‚ö†Ô∏è TROPPE ANOMALIE: {len(anomalies)} su {total_analyzed} ({anomaly_rate:.0f}%)
                                    
                                    1 recensione su 5 √® STRANA. Possibili cause:
                                    - Review bombing (attacchi coordinati)
                                    - Clienti di nicchia con esigenze uniche
                                    - Problemi sporadici ma gravi
                                    """)
                                
                                # Mostra le anomalie pi√π estreme
                                for i, anomaly in enumerate(anomalies[:3], 1):
                                    isolation = anomaly.get('isolation_score', 0)
                                    anomaly_type = anomaly.get('anomaly_type', 'unknown')
                                    preview = anomaly.get('text_preview', '')
                                    
                                    if isolation > 0.9:
                                        severity = "üî¥ ESTREMA"
                                        desc = "Completamente diversa da TUTTO il resto"
                                    elif isolation > 0.7:
                                        severity = "üü° ALTA"
                                        desc = "Molto diversa dalla norma"
                                    else:
                                        severity = "üîµ MODERATA"
                                        desc = "Abbastanza insolita"
                                    
                                    with st.expander(f"Anomalia #{i} - {severity} (tipo: {anomaly_type})"):
                                        st.warning(f"{desc} - Isolation score: {isolation:.2f}")
                                        st.caption(f"Testo: {preview}")
                                        
                                        # Suggerimenti basati sul tipo
                                        if anomaly_type == 'potential_spam':
                                            st.error("üö´ Possibile SPAM - verifica e segnala")
                                        elif anomaly_type == 'completely_isolated':
                                            st.info("üëÅÔ∏è Esperienza unica - potrebbe nascondere insight prezioso")
                                        elif anomaly_type == 'highly_emotional':
                                            st.warning("üò§ Molto emotiva - cliente molto arrabbiato o entusiasta")
                            
                            # DUPLICATI DINAMICI
                            if duplicates:
                                st.markdown("### üîÑ Possibili recensioni DUPLICATE:")
                                
                                for dup in duplicates[:3]:
                                    sim_score = dup.get('similarity_score', 0)
                                    
                                    if sim_score > 0.95:
                                        st.error(f"üö® QUASI IDENTICHE (similarit√† {sim_score:.2f}) - Probabilmente copia-incolla")
                                    elif sim_score > 0.9:
                                        st.warning(f"‚ö†Ô∏è Molto simili ({sim_score:.2f}) - Sospette")
                                    else:
                                        st.info(f"üìã Simili ({sim_score:.2f}) - Potrebbero essere genuine")
                                    
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.caption("Review 1:")
                                        st.text(dup.get('text_1_preview', ''))
                                    with col2:
                                        st.caption("Review 2:")
                                        st.text(dup.get('text_2_preview', ''))
                                    
                                    st.markdown("---")
                            
                            # QUALITY ASSESSMENT DINAMICO
                            quality = similarity_data.get('embedding_quality', {})
                            if quality:
                                overall_quality = quality.get('overall_quality_score', 0)
                                grade = quality.get('quality_grade', 'Unknown')
                                
                                if overall_quality > 0.8:
                                    st.success(f"""
                                    ‚úÖ Analisi di ALTISSIMA QUALIT√Ä (score: {overall_quality:.2f})
                                    
                                    I pattern identificati sono affidabili e actionable.
                                    Puoi fidarti di questi cluster per segmentare i clienti.
                                    """)
                                elif overall_quality < 0.4:
                                    st.error(f"""
                                    ‚ùå Analisi di BASSA QUALIT√Ä (score: {overall_quality:.2f})
                                    
                                    I dati sono troppo confusi o scarsi per trarre conclusioni.
                                    Raccogli pi√π recensioni prima di prendere decisioni.
                                    """)
                    else:
                        st.warning(f"‚ö†Ô∏è {similarity_data.get('error', 'Semantic analysis non disponibile')}")
                
                # ==================== FINE MODIFICHE DINAMICHE ====================
                
                # Reset Enterprise Analysis button
                st.markdown("---")
                if st.button("üîÑ Reset Enterprise Analysis", use_container_width=True):
                    if 'enterprise_analysis' in st.session_state.reviews_data:
                        del st.session_state.reviews_data['enterprise_analysis']
                    st.success("Enterprise analysis reset completato!")
                    time.sleep(1)
                    st.rerun()
        
        # ============================================================================
        # SEZIONE AI INSIGHTS ESISTENTE (mantieni tutto uguale)
        # ============================================================================
        
        st.markdown("---")
        st.markdown("### ü§ñ TRADITIONAL AI INSIGHTS")
        
        # Controlla se l'analisi AI √® gi√† stata fatta
        if st.session_state.reviews_data.get('ai_insights'):
            ai_results = st.session_state.reviews_data['ai_insights']
            
            if isinstance(ai_results, dict) and 'error' not in ai_results:
                # Executive Summary Multi-Platform
                executive = ai_results.get('executive_summary', {})
                if executive:
                    st.markdown("### üéØ Multi-Platform Executive Summary")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        create_metric_card("üè• Overall Health", f"{executive.get('overall_health_score', 'N/A')}/100")
                    with col2:
                        st.markdown("**üéØ Main Opportunity:**")
                        st.info(executive.get('main_opportunity', 'N/A'))
                    with col3:
                        st.markdown("**üîÑ Platform Consistency:**")
                        st.success(executive.get('platform_consistency', 'N/A'))
                    
                    st.markdown("**üí° Cross-Platform Key Insights:**")
                    for insight in executive.get('key_insights', []):
                        st.markdown(f"- {insight}")
                    
                    if executive.get('urgent_issues'):
                        st.warning(f"üö® **Issues Urgenti:** {executive['urgent_issues']}")
                
                # Platform Analysis
                platform_analysis = ai_results.get('platform_analysis', {})
                if platform_analysis:
                    st.markdown("---")
                    st.markdown("### üåç Platform-Specific Analysis")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.success(f"üèÜ **Strongest Platform:** {platform_analysis.get('strongest_platform', 'N/A')}")
                    with col2:
                        st.error(f"‚ö†Ô∏è **Needs Attention:** {platform_analysis.get('weakest_platform', 'N/A')}")
                    
                    # Platform specific insights
                    platform_insights = platform_analysis.get('platform_specific_insights', [])
                    if platform_insights:
                        for insight in platform_insights:
                            with st.expander(f"üîç {insight.get('platform', 'Unknown Platform')} - Detailed Insights"):
                                st.markdown(f"**üë• Audience Type:** {insight.get('audience_type', 'N/A')}")
                                st.markdown(f"**üéØ Unique Characteristics:** {insight.get('unique_characteristics', 'N/A')}")
                                st.markdown(f"**üìà Optimization Strategy:** {insight.get('optimization_strategy', 'N/A')}")
                
                # Cross-Platform Tabs
                ai_tabs = st.tabs([
                    "üîÑ Cross-Platform Analysis", "üí™ Strengths", "‚ö†Ô∏è Weaknesses", 
                    "üéØ Recommendations", "üë• Customer Journey", "üé® Content Strategy"
                ])
                
                with ai_tabs[0]:  # Cross-Platform Analysis
                    cross_platform = ai_results.get('cross_platform_sentiment', {})
                    if cross_platform:
                        st.markdown("**üîÑ Cross-Platform Sentiment Consistency:**")
                        st.info(cross_platform.get('sentiment_consistency', 'N/A'))
                        
                        if cross_platform.get('platform_reputation_gaps'):
                            st.markdown("**üìä Platform Reputation Gaps:**")
                            for gap in cross_platform['platform_reputation_gaps']:
                                st.markdown(f"- {gap}")
                
                with ai_tabs[1]:  # Strengths
                    strengths = ai_results.get('strengths_analysis', {})
                    if strengths and strengths.get('top_5_strengths'):
                        for strength in strengths['top_5_strengths']:
                            with st.expander(f"üí™ {strength.get('strength', 'N/A')}"):
                                st.markdown(f"**Evidence by Platform:** {strength.get('evidence_by_platform', 'N/A')}")
                                st.markdown(f"**Frequency:** {strength.get('frequency', 'N/A')}")
                                st.markdown(f"**Business Impact:** {strength.get('business_impact', 'N/A')}")
                                st.markdown(f"**Amplification Strategy:** {strength.get('amplification_strategy', 'N/A')}")
                
                with ai_tabs[2]:  # Weaknesses
                    weaknesses = ai_results.get('weaknesses_analysis', {})
                    if weaknesses and weaknesses.get('top_5_weaknesses'):
                        for weakness in weaknesses['top_5_weaknesses']:
                            priority_color = {
                                'Alta': 'red',
                                'Media': 'orange',
                                'Bassa': 'green'
                            }.get(weakness.get('priority', 'Media'), 'gray')
                            
                            with st.expander(f"‚ö†Ô∏è {weakness.get('weakness', 'N/A')} - Priority: :{priority_color}[{weakness.get('priority', 'N/A')}]"):
                                st.markdown(f"**Platform Specificity:** {weakness.get('platform_specificity', 'N/A')}")
                                st.markdown(f"**Evidence:** {weakness.get('evidence', 'N/A')}")
                                st.markdown(f"**Business Impact:** {weakness.get('business_impact', 'N/A')}")
                                st.markdown(f"**Solution Strategy:** {weakness.get('solution_strategy', 'N/A')}")
                
                with ai_tabs[3]:  # Recommendations
                    recommendations = ai_results.get('actionable_recommendations', {})
                    if recommendations:
                        if recommendations.get('immediate_actions'):
                            st.markdown("### üöÄ Immediate Actions")
                            for action in recommendations['immediate_actions']:
                                with st.expander(f"üéØ {action.get('action', 'N/A')}"):
                                    st.markdown(f"**Target Platforms:** {', '.join(action.get('target_platforms', []))}")
                                    st.markdown(f"**Timeline:** {action.get('timeline', 'N/A')}")
                                    st.markdown(f"**Resources Needed:** {action.get('resources_needed', 'N/A')}")
                                    st.markdown(f"**Expected Impact:** {action.get('expected_impact', 'N/A')}")
                                    st.markdown(f"**Success Metrics:** {action.get('success_metrics', 'N/A')}")
                
                with ai_tabs[4]:  # Customer Journey
                    journey = ai_results.get('customer_journey_analysis', {})
                    if journey:
                        if journey.get('touchpoint_mapping'):
                            st.markdown("**üó∫Ô∏è Customer Touchpoint Mapping:**")
                            for touchpoint in journey['touchpoint_mapping']:
                                st.markdown(f"- {touchpoint}")
                        
                        if journey.get('platform_role_analysis'):
                            roles = journey['platform_role_analysis']
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.markdown("**üîç Discovery Platforms:**")
                                for platform in roles.get('discovery_platforms', []):
                                    st.markdown(f"- {platform}")
                            with col2:
                                st.markdown("**‚öñÔ∏è Evaluation Platforms:**")
                                for platform in roles.get('evaluation_platforms', []):
                                    st.markdown(f"- {platform}")
                            with col3:
                                st.markdown("**‚úÖ Decision Platforms:**")
                                for platform in roles.get('decision_platforms', []):
                                    st.markdown(f"- {platform}")
                
                with ai_tabs[5]:  # Content Strategy
                    content = ai_results.get('content_marketing_insights', {})
                    if content:
                        if content.get('platform_content_strategy'):
                            st.markdown("### üìù Platform-Specific Content Strategy")
                            for strategy in content['platform_content_strategy']:
                                with st.expander(f"üì± {strategy.get('platform', 'N/A')} Strategy"):
                                    st.markdown(f"**Content Type:** {strategy.get('content_type', 'N/A')}")
                                    st.markdown(f"**Messaging:** {strategy.get('messaging', 'N/A')}")
                                    st.markdown(f"**Frequency:** {strategy.get('frequency', 'N/A')}")
            
            else:
                # Mostra errore AI
                st.error(f"Errore nell'analisi AI: {ai_results.get('error', 'Errore sconosciuto')}")
                
                if st.button("üîÑ Riprova Analisi AI"):
                    st.session_state.reviews_data['ai_insights'] = ""
                    st.rerun()
        
        else:
            # Avvia analisi AI multi-platform
            st.markdown("### üöÄ Avvia AI Analysis - Multi-Platform")
            st.info("L'analisi AI fornir√† insights strategici cross-platform basati su tutti i dati raccolti.")
            
            # Mostra preview dei dati che saranno analizzati
            with st.expander("üìã Preview Dati per AI Analysis"):
                for platform, analysis in analysis_results.items():
                    if analysis and analysis.get('total', 0) > 0:
                        platform_name = platform.replace('_analysis', '').title()
                        st.markdown(f"- **{platform_name}**: {analysis['total']} items, Rating: {analysis.get('avg_rating', 0):.2f}/5")
            
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("üß† Generate Multi-Platform AI Insights", type="primary", use_container_width=True):
                    with st.spinner("ü§ñ Elaborazione AI multi-platform in corso... (60-90 secondi)"):
                        # Prepara dati completi per AI
                        complete_data_for_ai = {
                            'trustpilot_reviews': st.session_state.reviews_data['trustpilot_reviews'],
                            'google_reviews': st.session_state.reviews_data['google_reviews'],
                            'tripadvisor_reviews': st.session_state.reviews_data['tripadvisor_reviews'],
                            'extended_reviews': st.session_state.reviews_data['extended_reviews'],
                            'reddit_discussions': st.session_state.reviews_data['reddit_discussions'],
                            'analysis_results': analysis_results
                        }
                        
                        # Analisi AI multi-platform
                        ai_results = analyze_with_openai_multiplatform(complete_data_for_ai)
                        st.session_state.reviews_data['ai_insights'] = ai_results
                        
                        if isinstance(ai_results, dict) and 'error' not in ai_results:
                            show_message("üéâ Multi-Platform AI Analysis completata con successo!", "success")
                        else:
                            show_message(f"‚ùå Errore nell'analisi AI: {ai_results.get('error', 'Errore sconosciuto')}", "error")
                        
                        time.sleep(2)
                        st.rerun()

with tab4:  # Brand Keywords Analysis
    st.markdown("### üîç Brand Keywords Intelligence")
    st.markdown("Analizza come gli utenti cercano il tuo brand su Google")
    
    # Input Brand Name
    col1, col2 = st.columns([2, 1])
    
    with col1:
        brand_name = st.text_input(
            "üìù Nome del Brand",
            placeholder="Es: Hotel Excelsior Roma",
            help="Inserisci il nome del brand da analizzare"
        )
        
        # Seed keywords suggestions
        if brand_name:
            suggested_seeds = [
                brand_name,
                f"{brand_name} recensioni",
                f"{brand_name} opinioni",
                f"{brand_name} prezzi",
                f"{brand_name} come funziona"
            ]
            
            st.markdown("**üéØ Seed Keywords Suggerite:**")
            seed_keywords = st.text_area(
                "Modifica o aggiungi seed keywords:",
                value="\n".join(suggested_seeds),
                height=150
            )
    
    with col2:
        st.markdown("**üîß Filtri Keywords**")
        
        # Include filters
        include_terms = st.text_area(
            "‚úÖ INCLUDI solo keywords con:",
            placeholder="recensioni\nopinioni\ncome",
            height=80
        )
        
        # Exclude filters
        exclude_terms = st.text_area(
            "‚ùå ESCLUDI keywords con:",
            placeholder="gratis\ncrack\ncompetitor",
            height=80
        )
        
        # Location settings
        location_options = {
            "Italia": 2380,
            "Stati Uniti": 2840,
            "Regno Unito": 2826,
            "Germania": 2276,
            "Francia": 2250,
            "Spagna": 2724
        }
        
        location = st.selectbox(
            "üåç Paese",
            list(location_options.keys()),
            index=0
        )
        location_code = location_options[location]
    

# Search button 
if st.button("üöÄ Analizza Brand Keywords", type="primary", use_container_width=True):
    if not brand_name:
        st.error("Inserisci il nome del brand!")
    else:
        with st.spinner("üîç Ricerca keywords in corso..."):
            # Initialize keywords extractor
            keywords_extractor = DataForSEOKeywordsExtractor(
                DFSEO_LOGIN, 
                DFSEO_PASS
            )
            
            # Get keywords
            seeds = [s.strip() for s in seed_keywords.split('\n') if s.strip()]
            include = [t.strip() for t in include_terms.split('\n') if t.strip()] if include_terms else None
            exclude = [t.strip() for t in exclude_terms.split('\n') if t.strip()] if exclude_terms else None
            
            df_keywords = keywords_extractor.get_keywords_for_keywords(
                seeds,
                location_code=location_code,
                include_terms=include,
                exclude_terms=exclude
            )
            
            if df_keywords is not None and len(df_keywords) > 0:
                # Salva le keywords
                st.session_state.reviews_data['brand_keywords']['raw_keywords'] = df_keywords.to_dict('records')
                
                # IMPORTANTE: Salva anche il brand_name e altri parametri di ricerca
                st.session_state.reviews_data['brand_keywords']['search_params'] = {
                    'brand_name': brand_name,
                    'location': location,
                    'seed_keywords': seeds,
                    'timestamp': datetime.now().isoformat()
                }
                
                st.success(f"‚úÖ Trovate {len(df_keywords)} keywords per '{brand_name}'!")
                st.rerun()
            else:
                st.error("‚ùå Nessuna keyword trovata. Prova con seed keywords diverse.")
    
# Visualizzazione e Analisi Keywords
if st.session_state.reviews_data['brand_keywords']['raw_keywords']:
    keywords_data = pd.DataFrame(st.session_state.reviews_data['brand_keywords']['raw_keywords'])
    
    # DEFINISCI LE FUNZIONI QUI, ALL'INIZIO
    def format_number(num):
        """Formatta i numeri per la visualizzazione"""
        if pd.isna(num) or num is None:
            return "N/A"
        if isinstance(num, (int, float)):
            return f"{num:,.0f}" if num >= 1 else f"{num:.2f}"
        return str(num)

    def format_currency(num):
        """Formatta la valuta per la visualizzazione"""
        if pd.isna(num) or num is None:
            return "N/A"
        if isinstance(num, (int, float)):
            return f"‚Ç¨{num:.2f}"
        return str(num)
    
    # Recupera il brand_name salvato durante la ricerca
    search_params = st.session_state.reviews_data['brand_keywords'].get('search_params', {})
    brand_name = search_params.get('brand_name', '')
    
    # Se per qualche motivo non c'√®, mostra un input per inserirlo
    if not brand_name:
        st.warning("‚ö†Ô∏è Nome del brand non trovato nei parametri di ricerca.")
        brand_name = st.text_input(
            "üìù Inserisci il nome del brand per l'analisi:",
            placeholder="Es: Nike, Adidas, etc.",
            key="brand_name_manual_input"
        )
    else:
        # Mostra il brand name recuperato (non editabile)
        st.info(f"üè∑Ô∏è Analisi keywords per: **{brand_name}**")
    
    # Metriche Overview
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üîç Keywords Totali", len(keywords_data))
    with col2:
        total_volume = keywords_data['search_volume'].sum()
        st.metric("üìä Volume Totale", f"{total_volume:,}")
    with col3:
        avg_cpc = keywords_data['cpc'].mean()
        st.metric("üí∞ CPC Medio", f"‚Ç¨{avg_cpc:.2f}")
    with col4:
        # FIX: Gestisci caso in cui brand_name √® vuoto
        if brand_name:
            brand_queries = keywords_data[keywords_data['keyword'].str.contains(brand_name.lower(), case=False, na=False)]
            st.metric("üè∑Ô∏è Brand Queries", len(brand_queries))
        else:
            st.metric("üè∑Ô∏è Brand Queries", "N/A")
    
    # SEZIONE: Mostra TUTTE le Keywords
    st.markdown("### üìä Tutte le Keywords Trovate")
    
    # Opzioni di visualizzazione
    col1, col2, col3 = st.columns(3)
    with col1:
        sort_by = st.selectbox(
            "Ordina per:",
            ["search_volume", "cpc", "keyword", "competition_level"],
            index=0
        )
    with col2:
        sort_order = st.radio(
            "Ordine:",
            ["Decrescente", "Crescente"],
            horizontal=True
        )
    with col3:
        show_top = st.number_input(
            "Mostra prime N keywords (0 = tutte):",
            min_value=0,
            value=0,
            step=10
        )
    
# Applica ordinamento
    ascending = sort_order == "Crescente"
    sorted_df = keywords_data.sort_values(sort_by, ascending=ascending, na_position='last')
    
    # Limita se richiesto
    if show_top > 0:
        display_all_df = sorted_df.head(show_top)
    else:
        display_all_df = sorted_df.copy()
    
    # Formatta per visualizzazione
    formatted_all_df = display_all_df.copy()
    formatted_all_df['search_volume'] = formatted_all_df['search_volume'].apply(format_number)
    formatted_all_df['cpc'] = formatted_all_df['cpc'].apply(format_currency)
    
    # Mostra tabella con st.table (SEMPRE VISIBILE)
    st.table(formatted_all_df[['keyword', 'search_volume', 'cpc', 'competition_level']])
    
    # Download CSV
    csv = keywords_data.to_csv(index=False, encoding='utf-8')
    st.download_button(
        label="üì• Scarica Tutte le Keywords (CSV)",
        data=csv,
        file_name=f"keywords_{brand_name}_{datetime.now().strftime('%Y%m%d')}.csv",
        mime="text/csv",
        use_container_width=True
    )
    
    st.markdown("---")
    
    # Categorizzazione Keywords
    st.markdown("### üìÇ Categorizzazione Automatica")
    
    # Definisci le categorie
    categories = {
        'informational': ['chi','cosa','che cos‚Äô√®','come','dove','quando','perch√©','quale','quali','quanto','quanta','quali sono','definizione','significato','spiegazione','descrizione','guida','tutorial','manuale','istruzioni','procedura','step by step','passo per passo','video tutorial','esempio','esempi di codice','consiglio','consigli','trucchi','tips','metodi','strategie','tecniche','idee','ispirazione','storia di','origine','evoluzione','fatti su','curiosit√†'],
        'navigational': ['sito','sito ufficiale','homepage','dominio','URL','www.','.com','.it','login','accedi','accesso','registrati','signup','sign in','area riservata','dashboard','profilo','contatti','telefono','email','assistenza','supporto','help','mappa','indirizzo','orari','chi siamo','about us'],
        'transactional': ['comprare','acquistare','ordina','ordinare','prenotare','book','iscriviti','registrati','abbonarsi','subscribe','prezzo','prezzi','costo','costi','tariffa','tassa','sconto','offerta','offerte','promozione','promo','coupon','codice sconto','saldi','deal','deal del giorno','shop','store','negozio online','e-commerce','checkout','carrello','spedizione gratuita','res o gratuiti','pagamento a rate','dove comprare','dove acquistare','miglior prezzo','comparazione prezzi','rivenditore','distributore','locale'],
        'reviews': ['recensione','recensioni','review','reviews','valutazione','voto','stelline','rating','feedback','opinione','opinioni','parere','pareri','esperienza','esperienze','testimonianza','testimonials','pro e contro','vantaggi','svantaggi','punto di forza','punto debole','motivi per','motivi contro'],
        'comparison': ['vs','contro','vs.','o','oppure','vs vs','differenza','differenze','differenze tra','confronto','confronti','meglio','migliore','migliori','peggiore','peggiori','top','classifica','ranking','miglior [^ ]+','i migliori','i top','best of','lista','elenco'],
        'problems': ['problema','problemi','errore','bug','malfunzionamento','crash','blocco','impossibile avviare','non funziona','si blocca','truffa','truffe','truffaldino','lamentele','reclamo','assistenza','supporto clienti','help desk','richiedere supporto','riparazione','riparare','manutenzione','guasto','assistenza tecnica']
    }
    
    # Categorizza keywords
    for category, terms in categories.items():
        mask = keywords_data['keyword'].str.lower().str.contains('|'.join(terms), na=False)
        category_kws = keywords_data[mask]
        
        if len(category_kws) > 0:
            with st.expander(f"üìÅ {category.title()} ({len(category_kws)} keywords)"):
                # Formatta i dati per la visualizzazione
                display_df = category_kws[['keyword', 'search_volume', 'cpc', 'competition_level']].copy()
                display_df['search_volume'] = display_df['search_volume'].apply(format_number)
                display_df['cpc'] = display_df['cpc'].apply(format_currency)
                
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    hide_index=True,
                    height=300
                )
    
    # Bottone per AI Analysis - DENTRO IL BLOCCO IF
    st.markdown("---")
    if st.button("üß† Genera AI Insights su Brand Keywords", type="primary", use_container_width=True):
        if not brand_name or brand_name.strip() == "":
            st.error("‚ùå Inserisci il nome del brand prima di generare l'analisi!")
        else:
            with st.spinner("ü§ñ Analisi AI in corso..."):
                # Prepara dati per AI nel formato corretto
                keywords_for_ai = {
                    'brand_name': brand_name,
                    'total_keywords': len(keywords_data),
                    'total_search_volume': int(keywords_data['search_volume'].sum()),
                    'avg_cpc': float(keywords_data['cpc'].mean()),
                    'categories': {},
                    'all_keywords': keywords_data.to_dict('records')
                }
                
                # Aggiungi keywords per categoria
                for category, terms in categories.items():
                    mask = keywords_data['keyword'].str.lower().str.contains('|'.join(terms), na=False)
                    category_kws = keywords_data[mask]
                    if len(category_kws) > 0:
                        keywords_for_ai['categories'][category] = category_kws.to_dict('records')
                
                # Salva i parametri di ricerca
                st.session_state.reviews_data['brand_keywords']['search_params'] = {
                    'brand_name': brand_name,
                    'timestamp': datetime.now().isoformat()
                }
                
                # Chiama la funzione AI
                try:
                    ai_insights = analyze_brand_keywords_with_ai(keywords_for_ai, brand_name)
                    
                    # Salva i risultati
                    st.session_state.reviews_data['brand_keywords']['ai_insights'] = ai_insights
                    
                    st.success("‚úÖ AI Analysis completata!")
                    time.sleep(1)
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"‚ùå Errore durante l'analisi AI: {str(e)}")
                    logger.error(f"Errore in AI Keywords Analysis: {str(e)}", exc_info=True)
    
    # Mostra risultati AI se disponibili
    if st.session_state.reviews_data['brand_keywords']['ai_insights']:
        insights = st.session_state.reviews_data['brand_keywords']['ai_insights']
        
        # Controlla il tipo di insights
        if isinstance(insights, str):
            # NUOVO FORMATO: Testo narrativo
            st.markdown("### üìä Analisi Strategica Brand Keywords")
            
            # Container con stile per migliore leggibilit√†
            with st.container():
                # Dividi il testo in sezioni e formatta
                sections = insights.split('\n\n')
                
                for section in sections:
                    if section.strip():
                        # Identifica titoli di sezione
                        lines = section.strip().split('\n')
                        first_line = lines[0].strip()
                        
                        # Se √® un titolo numerato (es. "1. ANALISI DELLA DOMANDA")
                        if first_line and first_line[0].isdigit() and '. ' in first_line:
                            st.markdown(f"### {first_line}")
                            # Mostra il resto della sezione
                            if len(lines) > 1:
                                remaining_text = '\n'.join(lines[1:])
                                st.markdown(remaining_text)
                        
                        # Se √® un titolo in maiuscolo
                        elif first_line.isupper() and len(first_line.split()) < 5:
                            st.markdown(f"**{first_line}**")
                            if len(lines) > 1:
                                remaining_text = '\n'.join(lines[1:])
                                st.markdown(remaining_text)
                        
                        # Altrimenti mostra come testo normale
                        else:
                            st.markdown(section)
            
            # Azioni disponibili
            st.markdown("---")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("üîÑ Rigenera Analisi", use_container_width=True):
                    st.session_state.reviews_data['brand_keywords']['ai_insights'] = {}
                    st.success("‚úÖ Analisi resettata")
                    st.rerun()
            
            with col2:
                if st.button("üì• Esporta Analisi", use_container_width=True):
                    # Prepara testo per export
                    export_text = f"ANALISI BRAND KEYWORDS - {brand_name}\n\n"
                    export_text += f"Data: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n"
                    export_text += f"Keywords analizzate: {len(keywords_data)}\n"
                    export_text += f"Volume totale: {keywords_data['search_volume'].sum():,}\n"
                    export_text += f"CPC medio: ‚Ç¨{keywords_data['cpc'].mean():.2f}\n\n"
                    export_text += "="*50 + "\n\n"
                    export_text += insights
                    
                    st.download_button(
                        label="üíæ Download TXT",
                        data=export_text,
                        file_name=f"analisi_keywords_{brand_name}_{datetime.now().strftime('%Y%m%d')}.txt",
                        mime="text/plain"
                    )
        
        elif isinstance(insights, dict):
            # VECCHIO FORMATO JSON - Compatibilit√†
            if 'error' in insights:
                st.error(f"‚ùå Errore nell'analisi: {insights['error']}")
            else:
                st.warning("‚ö†Ô∏è Formato analisi obsoleto. Rigenera per il nuovo formato.")

else:
    # Se non ci sono keywords caricate
    st.info("üîç Nessuna keyword caricata. Usa la sezione sopra per cercare keywords del brand.")
    
# Mostra risultati AI se disponibili
    if st.session_state.reviews_data['brand_keywords']['ai_insights']:
        insights = st.session_state.reviews_data['brand_keywords']['ai_insights']
        
        # Controlla il tipo di insights
        if isinstance(insights, str):
            # NUOVO FORMATO: Testo narrativo
            st.markdown("### üìä Analisi Strategica Brand Keywords")
            
            # Container con stile per migliore leggibilit√†
            with st.container():
                # Dividi il testo in sezioni e formatta
                sections = insights.split('\n\n')
                
                for section in sections:
                    if section.strip():
                        # Identifica titoli di sezione
                        lines = section.strip().split('\n')
                        first_line = lines[0].strip()
                        
                        # Se √® un titolo numerato (es. "1. ANALISI DELLA DOMANDA")
                        if first_line and first_line[0].isdigit() and '. ' in first_line:
                            st.markdown(f"### {first_line}")
                            # Mostra il resto della sezione
                            if len(lines) > 1:
                                remaining_text = '\n'.join(lines[1:])
                                st.markdown(remaining_text)
                        
                        # Se √® un titolo in maiuscolo
                        elif first_line.isupper() and len(first_line.split()) < 5:
                            st.markdown(f"**{first_line}**")
                            if len(lines) > 1:
                                remaining_text = '\n'.join(lines[1:])
                                st.markdown(remaining_text)
                        
                        # Altrimenti mostra come testo normale
                        else:
                            st.markdown(section)
                
                # Aggiungi metriche chiave se presenti nel testo
                st.markdown("---")
                
                # Box riassuntivo con i numeri principali (se li abbiamo)
                if 'total_keywords' in st.session_state.reviews_data['brand_keywords']:
                    kw_data = st.session_state.reviews_data['brand_keywords']
                    raw_keywords = kw_data.get('raw_keywords', [])
                    
                    if raw_keywords:
                        df = pd.DataFrame(raw_keywords)
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("üîç Keywords Totali", len(df))
                        with col2:
                            st.metric("üìä Volume Totale", f"{df['search_volume'].sum():,}")
                        with col3:
                            st.metric("üí∞ CPC Medio", f"‚Ç¨{df['cpc'].mean():.2f}")
                        with col4:
                            # Conta keywords branded
                            brand_name = kw_data.get('search_params', {}).get('brand_name', '')
                            if brand_name:
                                branded_count = df['keyword'].str.contains(brand_name.lower(), case=False).sum()
                                st.metric("üè∑Ô∏è Keywords Branded", branded_count)
        
        elif isinstance(insights, dict):
            # VECCHIO FORMATO JSON - Mantieni per compatibilit√†
            if 'error' in insights:
                st.error(f"‚ùå Errore nell'analisi: {insights['error']}")
            else:
                st.warning("‚ö†Ô∏è Formato analisi obsoleto rilevato. Rigenera l'analisi per il nuovo formato.")
                
                # Mostra comunque i dati principali se ci sono
                if 'brand_perception' in insights:
                    st.markdown("### üé≠ Brand Perception")
                    perception = insights['brand_perception']
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        if perception.get('strengths'):
                            st.markdown("**üí™ Punti di Forza:**")
                            for s in perception['strengths']:
                                st.markdown(f"- {s}")
                    
                    with col2:
                        if perception.get('concerns'):
                            st.markdown("**üòü Preoccupazioni:**")
                            for c in perception['concerns']:
                                st.markdown(f"- {c}")
        
        # Azioni disponibili
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üîÑ Rigenera Analisi", use_container_width=True):
                st.session_state.reviews_data['brand_keywords']['ai_insights'] = {}
                st.success("‚úÖ Analisi resettata")
                st.rerun()
        
        with col2:
            if st.button("üì• Esporta Analisi", use_container_width=True):
                # Prepara testo per export
                export_text = f"ANALISI BRAND KEYWORDS\n\n"
                export_text += f"Data: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"
                
                if isinstance(insights, str):
                    export_text += insights
                else:
                    export_text += str(insights)
                
                st.download_button(
                    label="üíæ Download TXT",
                    data=export_text,
                    file_name=f"analisi_keywords_{datetime.now().strftime('%Y%m%d')}.txt",
                    mime="text/plain"
                )
        
        with col3:
            # Mostra/nascondi dati raw
            if st.button("üìä Mostra Dati Raw", use_container_width=True):
                with st.expander("Raw Data"):
                    st.json(st.session_state.reviews_data['brand_keywords'])
                    
with tab5:  # Visualizations
   st.markdown("### üìà Multi-Platform Visualizations")
   
   analysis_results = st.session_state.reviews_data.get('analysis_results', {})
   
   if not analysis_results:
       st.info("üìä Completa prima l'analisi multi-platform per vedere le visualizzazioni")
   else:
       # Crea visualizzazioni multi-platform
       charts = create_multiplatform_visualizations({'analysis_results': analysis_results})
       
       if charts:
           # Platform Distribution
           if 'platform_distribution' in charts:
               st.plotly_chart(charts['platform_distribution'], use_container_width=True)
           
           # Cross-Platform Sentiment
           if 'cross_platform_sentiment' in charts:
               st.plotly_chart(charts['cross_platform_sentiment'], use_container_width=True)
           
           # Platform Ratings Comparison
           if 'platform_ratings' in charts:
               st.plotly_chart(charts['platform_ratings'], use_container_width=True)
           
           # Additional charts section
           st.markdown("---")
           st.markdown("#### üìä Platform Breakdown")
           
           col1, col2 = st.columns(2)
           
           with col1:
               # Rating distribution for main platform
               for platform, analysis in analysis_results.items():
                   if analysis and analysis.get('rating_distribution') and analysis.get('total', 0) > 0:
                       platform_name = platform.replace('_analysis', '').title()
                       
                       rating_dist = analysis['rating_distribution']
                       fig_rating = px.bar(
                           x=['1‚≠ê', '2‚≠ê', '3‚≠ê', '4‚≠ê', '5‚≠ê'],
                           y=[rating_dist['1_star'], rating_dist['2_stars'], rating_dist['3_stars'], 
                              rating_dist['4_stars'], rating_dist['5_stars']],
                           title=f'Rating Distribution - {platform_name}',
                           color=[rating_dist['1_star'], rating_dist['2_stars'], rating_dist['3_stars'], 
                                  rating_dist['4_stars'], rating_dist['5_stars']],
                           color_continuous_scale='RdYlGn'
                       )
                       fig_rating.update_layout(template='plotly_dark')
                       st.plotly_chart(fig_rating, use_container_width=True)
                       break  # Mostra solo il primo per spazio
           
           with col2:
               # Top themes word cloud simulation
               all_themes = {}
               for platform, analysis in analysis_results.items():
                   if analysis and analysis.get('top_themes'):
                       for theme, count in analysis['top_themes']:
                           all_themes[theme] = all_themes.get(theme, 0) + count
               
               if all_themes:
                   top_themes = sorted(all_themes.items(), key=lambda x: x[1], reverse=True)[:15]
                   
                   fig_themes = px.bar(
                       x=[theme[1] for theme in top_themes],
                       y=[theme[0] for theme in top_themes],
                       orientation='h',
                       title='Top Themes Cross-Platform',
                       color=[theme[1] for theme in top_themes],
                       color_continuous_scale='viridis'
                   )
                   fig_themes.update_layout(
                       template='plotly_dark',
                       yaxis={'categoryorder': 'total ascending'}
                   )
                   st.plotly_chart(fig_themes, use_container_width=True)
       
       else:
           st.warning("‚ö†Ô∏è Dati insufficienti per generare visualizzazioni")

with tab6:  # Export
   st.markdown("### üì• Multi-Platform Export & Download")
   
   # Verifica dati disponibili
   has_reviews = any([
       st.session_state.reviews_data['trustpilot_reviews'],
       st.session_state.reviews_data['google_reviews'],
       st.session_state.reviews_data['tripadvisor_reviews'],
       st.session_state.reviews_data['extended_reviews']['total_count'] > 0,
       st.session_state.reviews_data['reddit_discussions']
   ])
   
   has_analysis = bool(st.session_state.reviews_data.get('analysis_results'))
   has_ai = bool(st.session_state.reviews_data.get('ai_insights'))
   has_keywords = bool(st.session_state.reviews_data['brand_keywords']['raw_keywords'])
   
   if not has_reviews:
       st.info("üìù Importa prima alcuni dati per abilitare l'export")
   else:
       # Statistiche export multi-platform
       st.markdown("#### üìä Multi-Platform Data Available")
       
       col1, col2, col3, col4, col5, col6 = st.columns(6)
       
       with col1:
           tp_count = len(st.session_state.reviews_data['trustpilot_reviews'])
           create_metric_card("üåü Trustpilot", f"{tp_count}")
       with col2:
           g_count = len(st.session_state.reviews_data['google_reviews'])
           create_metric_card("üìç Google", f"{g_count}")
       with col3:
           ta_count = len(st.session_state.reviews_data['tripadvisor_reviews'])
           create_metric_card("‚úàÔ∏è TripAdvisor", f"{ta_count}")
       with col4:
           ext_count = st.session_state.reviews_data['extended_reviews']['total_count']
           create_metric_card("üîç Extended", f"{ext_count}")
       with col5:
           reddit_count = len(st.session_state.reviews_data['reddit_discussions'])
           create_metric_card("üí¨ Reddit", f"{reddit_count}")
       with col6:
           kw_count = len(st.session_state.reviews_data['brand_keywords']['raw_keywords'])
           create_metric_card("üîç Keywords", f"{kw_count}")
       
       # Status analysis e AI
       col1, col2, col3 = st.columns(3)
       with col1:
           analysis_status = "‚úÖ" if has_analysis else "‚ùå"
           create_metric_card("üìä Analysis", analysis_status)
       with col2:
           ai_status = "‚úÖ" if has_ai else "‚ùå"
           create_metric_card("ü§ñ AI Insights", ai_status)
       with col3:
           kw_status = "‚úÖ" if has_keywords else "‚ùå"
           create_metric_card("üîç Keywords AI", kw_status)
       
       st.markdown("---")
       
       # Opzioni di export multi-platform
       col1, col2, col3 = st.columns(3)
       
       with col1:
           st.markdown("#### üìÑ Complete Multi-Platform Report")
           st.markdown("Report Word completo con analisi cross-platform e AI insights")
           
           if st.button("üìÑ Generate Multi-Platform Report", type="primary", use_container_width=True):
               if not has_ai:
                   show_message("‚ö†Ô∏è Completa prima l'analisi AI per un report completo", "warning")
               
               with st.spinner("üìù Generazione report multi-platform..."):
                   try:
                       # Crea documento Word completo
                       doc = Document()
                       
                       # Header
                       doc.add_heading('Multi-Platform Brand Intelligence Report', 0)
                       doc.add_heading(f'Generated on {datetime.now().strftime("%d/%m/%Y at %H:%M")}', level=1)
                       
                       # Executive Summary
                       if has_ai and isinstance(st.session_state.reviews_data['ai_insights'], dict):
                           ai_data = st.session_state.reviews_data['ai_insights']
                           executive = ai_data.get('executive_summary', {})
                           
                           if executive:
                               doc.add_heading('Executive Summary', level=1)
                               doc.add_paragraph(f"Overall Health Score: {executive.get('overall_health_score', 'N/A')}/100")
                               doc.add_paragraph(f"Main Opportunity: {executive.get('main_opportunity', 'N/A')}")
                               doc.add_paragraph(f"Platform Consistency: {executive.get('platform_consistency', 'N/A')}")
                               
                               if executive.get('key_insights'):
                                   doc.add_heading('Key Cross-Platform Insights', level=2)
                                   for insight in executive['key_insights']:
                                       doc.add_paragraph(f"‚Ä¢ {insight}", style='List Bullet')
                       
                       # Brand Keywords Analysis (NUOVO)
                       if has_keywords and st.session_state.reviews_data['brand_keywords']['ai_insights']:
                           doc.add_heading('Brand Keywords Analysis', level=1)
                           kw_insights = st.session_state.reviews_data['brand_keywords']['ai_insights']
                           
                           # Brand Perception
                           perception = kw_insights.get('brand_perception', {})
                           doc.add_heading('Brand Perception from Search Queries', level=2)
                           doc.add_paragraph(f"Trust Level: {perception.get('trust_level', 'N/A')}")
                           
                           doc.add_heading('Strengths Identified', level=3)
                           for strength in perception.get('strengths', []):
                               doc.add_paragraph(f"‚Ä¢ {strength}", style='List Bullet')
                           
                           doc.add_heading('Concerns Identified', level=3)
                           for concern in perception.get('concerns', []):
                               doc.add_paragraph(f"‚Ä¢ {concern}", style='List Bullet')
                       
                       # Platform Data Summary
                       doc.add_heading('Platform Data Overview', level=1)
                       
                       platforms_summary = [
                           ('Trustpilot', tp_count),
                           ('Google Reviews', g_count), 
                           ('TripAdvisor', ta_count),
                           ('Extended Reviews', ext_count),
                           ('Reddit Discussions', reddit_count),
                           ('Brand Keywords', kw_count)  # NUOVO
                       ]
                       
                       for platform_name, count in platforms_summary:
                           if count > 0:
                               doc.add_heading(platform_name, level=2)
                               doc.add_paragraph(f"Total items: {count}")
                               
                               # Aggiungi analisi se disponibile
                               analysis_key = f"{platform_name.lower().replace(' ', '_')}_analysis"
                               if analysis_key in st.session_state.reviews_data.get('analysis_results', {}):
                                   analysis = st.session_state.reviews_data['analysis_results'][analysis_key]
                                   if analysis.get('avg_rating', 0) > 0:
                                       doc.add_paragraph(f"Average Rating: {analysis['avg_rating']:.2f}/5")
                                       doc.add_paragraph(f"Positive Sentiment: {analysis['sentiment_percentage']['positive']:.1f}%")
                       
                       # AI Insights sections
                       if has_ai and isinstance(st.session_state.reviews_data['ai_insights'], dict):
                           ai_data = st.session_state.reviews_data['ai_insights']
                           
                           # Platform Analysis
                           platform_analysis = ai_data.get('platform_analysis', {})
                           if platform_analysis:
                               doc.add_heading('Platform Performance Analysis', level=1)
                               doc.add_paragraph(f"Strongest Platform: {platform_analysis.get('strongest_platform', 'N/A')}")
                               doc.add_paragraph(f"Platform Needing Attention: {platform_analysis.get('weakest_platform', 'N/A')}")
                           
                           # Cross-Platform Recommendations
                           recommendations = ai_data.get('actionable_recommendations', {})
                           if recommendations:
                               doc.add_heading('Multi-Platform Recommendations', level=1)
                               
                               immediate = recommendations.get('immediate_actions', [])
                               if immediate:
                                   doc.add_heading('Immediate Actions', level=2)
                                   for action in immediate:
                                       doc.add_paragraph(f"‚Ä¢ {action.get('action', 'N/A')}", style='List Bullet')
                                       platforms = ', '.join(action.get('target_platforms', []))
                                       doc.add_paragraph(f"  Target Platforms: {platforms}")
                                       doc.add_paragraph(f"  Timeline: {action.get('timeline', 'N/A')}")
                                       doc.add_paragraph(f"  Expected Impact: {action.get('expected_impact', 'N/A')}")
                       
                       # Salva documento
                       filename = f"multiplatform_brand_intelligence_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
                       doc.save(filename)
                       
                       # Download
                       with open(filename, 'rb') as f:
                           st.download_button(
                               label="üì• Download Multi-Platform Report",
                               data=f.read(),
                               file_name=filename,
                               mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                               use_container_width=True
                           )
                       
                       # Cleanup
                       os.remove(filename)
                       show_message("üìÑ Multi-Platform Report generato con successo!", "success")
                       
                   except Exception as e:
                       show_message(f"Errore nella generazione del report: {str(e)}", "error")
       
       with col2:
           st.markdown("#### üìä Multi-Platform CSV Export")
           st.markdown("Esporta tutti i dati in CSV con identificazione piattaforma")
           
           if st.button("üìä Export Multi-Platform CSV", use_container_width=True):
               try:
                   # Prepara dati CSV unificati
                   csv_data = []
                   
                   # Trustpilot
                   for review in st.session_state.reviews_data['trustpilot_reviews']:
                       rating = review.get('rating', {})
                       rating_value = rating.get('value', 0) if isinstance(rating, dict) else (rating or 0)
                       
                       csv_data.append({
                           'platform': 'Trustpilot',
                           'rating': rating_value,
                           'text': review.get('review_text', '')[:500],
                           'date': review.get('timestamp', ''),
                           'reviewer': review.get('user', {}).get('name', 'Anonymous') if isinstance(review.get('user'), dict) else 'Anonymous',
                           'helpful_count': review.get('helpful_count', 0),
                           'source_detail': 'Trustpilot'
                       })
                   
                   # Google Reviews
                   for review in st.session_state.reviews_data['google_reviews']:
                       rating = review.get('rating', {})
                       rating_value = rating.get('value', 0) if isinstance(rating, dict) else (rating or 0)
                       
                       csv_data.append({
                           'platform': 'Google',
                           'rating': rating_value,
                           'text': review.get('review_text', '')[:500],
                           'date': review.get('timestamp', ''),
                           'reviewer': review.get('user', {}).get('name', 'Anonymous') if isinstance(review.get('user'), dict) else 'Anonymous',
                           'helpful_count': review.get('helpful_count', 0),
                           'source_detail': 'Google Reviews'
                       })
                   
                   # TripAdvisor
                   for review in st.session_state.reviews_data['tripadvisor_reviews']:
                       rating = review.get('rating', {})
                       rating_value = rating.get('value', 0) if isinstance(rating, dict) else (rating or 0)
                       
                       csv_data.append({
                           'platform': 'TripAdvisor',
                           'rating': rating_value,
                           'text': review.get('review_text', '')[:500],
                           'date': review.get('timestamp', ''),
                           'reviewer': review.get('user', {}).get('name', 'Anonymous') if isinstance(review.get('user'), dict) else 'Anonymous',
                           'helpful_count': review.get('helpful_count', 0),
                           'source_detail': 'TripAdvisor'
                       })
                   
                   # Extended Reviews (Yelp + Multi)
                   for review in st.session_state.reviews_data['extended_reviews']['all_reviews']:
                       rating = review.get('rating', {})
                       rating_value = rating.get('value', 0) if isinstance(rating, dict) else (rating or 0)
                       source_detail = review.get('review_source', 'Extended')
                       
                       csv_data.append({
                           'platform': 'Extended',
                           'rating': rating_value,
                           'text': review.get('review_text', '')[:500],
                           'date': review.get('timestamp', ''),
                           'reviewer': review.get('user', {}).get('name', 'Anonymous') if isinstance(review.get('user'), dict) else 'Anonymous',
                           'helpful_count': review.get('helpful_count', 0),
                           'source_detail': source_detail
                       })
                   
                   # Reddit Discussions
                   for discussion in st.session_state.reviews_data['reddit_discussions']:
                       csv_data.append({
                           'platform': 'Reddit',
                           'rating': 0,  # Reddit non ha rating
                           'text': f"{discussion.get('title', '')} {discussion.get('text', '')}"[:500],
                           'date': discussion.get('created_utc', ''),
                           'reviewer': discussion.get('author', 'Anonymous'),
                           'helpful_count': discussion.get('upvotes', 0),
                           'source_detail': f"r/{discussion.get('subreddit', 'unknown')}"
                       })
                   
                   if csv_data:
                       # Crea DataFrame
                       df = pd.DataFrame(csv_data)
                       csv_string = df.to_csv(index=False, encoding='utf-8')
                       
                       # Download
                       st.download_button(
                           label="üì• Download Multi-Platform CSV",
                           data=csv_string,
                           file_name=f"multiplatform_reviews_{datetime.now().strftime('%Y%m%d')}.csv",
                           mime="text/csv",
                           use_container_width=True
                       )
                       
                       # Mostra preview con platform breakdown
                       st.markdown("**Preview Multi-Platform CSV:**")
                       platform_counts = df['platform'].value_counts()
                       st.markdown("**Platform Distribution:**")
                       for platform, count in platform_counts.items():
                           st.markdown(f"- {platform}: {count} items")
                       
                       st.dataframe(df.head(10), use_container_width=True)
                       show_message(f"üìä Multi-Platform CSV generato con {len(csv_data)} items!", "success")
                   else:
                       show_message("‚ùå Nessun dato da esportare", "error")
                       
               except Exception as e:
                   show_message(f"Errore nell'export CSV: {str(e)}", "error")
       
       with col3:
           st.markdown("#### ü§ñ Complete AI Insights JSON")
           st.markdown("Esporta l'analisi AI completa multi-platform + keywords")
           
           if not has_ai:
               st.info("ü§ñ Completa prima l'analisi AI multi-platform")
           else:
               if st.button("ü§ñ Export Complete AI JSON", use_container_width=True):
                   ai_data = st.session_state.reviews_data['ai_insights']
                   
                   if isinstance(ai_data, dict) and 'error' not in ai_data:
                       # Aggiungi metadata al JSON
                       export_data = {
                           'metadata': {
                               'export_date': datetime.now().isoformat(),
                               'tool_version': 'Multi-Platform Reviews & Keywords Analyzer v2.1',
                               'platforms_analyzed': [],
                               'total_items': 0,
                               'has_keywords_analysis': has_keywords
                           },
                           'platform_data_summary': {},
                           'ai_insights': ai_data
                       }
                       
                       # Aggiungi Brand Keywords insights se disponibili
                       if has_keywords and st.session_state.reviews_data['brand_keywords']['ai_insights']:
                           export_data['brand_keywords_insights'] = st.session_state.reviews_data['brand_keywords']['ai_insights']
                           export_data['brand_keywords_stats'] = {
                               'total_keywords': len(st.session_state.reviews_data['brand_keywords']['raw_keywords']),
                               'brand_name': brand_name if 'brand_name' in locals() else 'N/A'
                           }
                       
                       # Aggiungi summary dei dati
                       analysis_results = st.session_state.reviews_data.get('analysis_results', {})
                       for platform, analysis in analysis_results.items():
                           if analysis and analysis.get('total', 0) > 0:
                               platform_name = platform.replace('_analysis', '')
                               export_data['metadata']['platforms_analyzed'].append(platform_name)
                               export_data['metadata']['total_items'] += analysis['total']
                               export_data['platform_data_summary'][platform_name] = {
                                   'total_items': analysis['total'],
                                   'avg_rating': analysis.get('avg_rating', 0),
                                   'positive_sentiment_percentage': analysis.get('sentiment_percentage', {}).get('positive', 0)
                               }
                       
                       # Formatta JSON
                       json_string = json.dumps(export_data, indent=2, ensure_ascii=False)
                       
                       # Download
                       st.download_button(
                           label="üì• Download Complete AI JSON",
                           data=json_string,
                           file_name=f"multiplatform_ai_insights_{datetime.now().strftime('%Y%m%d')}.json",
                           mime="application/json",
                           use_container_width=True
                       )
                       
                       # Preview
                       with st.expander("üëÄ Preview AI JSON Structure"):
                           st.json({
                               'metadata': export_data['metadata'],
                               'platform_data_summary': export_data['platform_data_summary'],
                               'ai_insights_sections': list(ai_data.keys()),
                               'has_brand_keywords': has_keywords
                           })
                       
                       show_message("ü§ñ Complete AI Insights esportati con successo!", "success")
                   else:
                       show_message("‚ùå Errore nei dati AI - impossibile esportare", "error")
       
       # Sezione export completo multi-platform
       st.markdown("---")
       st.markdown("#### üì¶ Complete Brand Intelligence Archive")
       st.markdown("Esporta tutti i dati, analisi e insights in un archivio completo")
       
       if st.button("üì¶ Generate Complete Brand Intelligence Archive", type="primary", use_container_width=True):
           if not (has_reviews and has_analysis):
               show_message("‚ö†Ô∏è Completa almeno import e analisi per l'export completo", "warning")
           else:
               with st.spinner("üì¶ Creazione archivio Brand Intelligence completo..."):
                   try:
                       import zipfile
                       import io
                       
                       # Crea archivio in memoria
                       zip_buffer = io.BytesIO()
                       
                       with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                           # 1. CSV Multi-Platform Unificato
                           csv_data = []
                           
                           # Combina tutti i dati con platform identification
                           for platform_name, data_key in [
                               ('Trustpilot', 'trustpilot_reviews'),
                               ('Google', 'google_reviews'), 
                               ('TripAdvisor', 'tripadvisor_reviews')
                           ]:
                               for review in st.session_state.reviews_data[data_key]:
                                   rating = review.get('rating', {})
                                   rating_value = rating.get('value', 0) if isinstance(rating, dict) else (rating or 0)
                                   csv_data.append({
                                       'platform': platform_name,
                                       'rating': rating_value,
                                       'text': review.get('review_text', ''),
                                       'date': review.get('timestamp', ''),
                                       'reviewer': review.get('user', {}).get('name', 'Anonymous') if isinstance(review.get('user'), dict) else 'Anonymous',
                                       'source_detail': platform_name
                                   })
                           
                           # Extended Reviews
                           for review in st.session_state.reviews_data['extended_reviews']['all_reviews']:
                               rating = review.get('rating', {})
                               rating_value = rating.get('value', 0) if isinstance(rating, dict) else (rating or 0)
                               csv_data.append({
                                   'platform': 'Extended',
                                   'rating': rating_value,
                                   'text': review.get('review_text', ''),
                                   'date': review.get('timestamp', ''),
                                   'reviewer': review.get('user', {}).get('name', 'Anonymous') if isinstance(review.get('user'), dict) else 'Anonymous',
                                   'source_detail': review.get('review_source', 'Extended')
                               })
                           
                           # Reddit
                           for discussion in st.session_state.reviews_data['reddit_discussions']:
                               csv_data.append({
                                   'platform': 'Reddit',
                                   'rating': 0,
                                   'text': f"{discussion.get('title', '')} {discussion.get('text', '')}",
                                   'date': discussion.get('created_utc', ''),
                                   'reviewer': discussion.get('author', 'Anonymous'),
                                   'source_detail': f"r/{discussion.get('subreddit', 'unknown')}"
                               })
                           
                           if csv_data:
                               df = pd.DataFrame(csv_data)
                               csv_content = df.to_csv(index=False, encoding='utf-8')
                               zip_file.writestr("multiplatform_reviews_data.csv", csv_content)
                           
                           # 2. Brand Keywords Data (NUOVO)
                           if has_keywords:
                               keywords_df = pd.DataFrame(st.session_state.reviews_data['brand_keywords']['raw_keywords'])
                               keywords_csv = keywords_df.to_csv(index=False)
                               zip_file.writestr("brand_keywords_data.csv", keywords_csv)
                               
                               # Keywords AI insights
                               if st.session_state.reviews_data['brand_keywords']['ai_insights']:
                                   keywords_insights = json.dumps(
                                       st.session_state.reviews_data['brand_keywords']['ai_insights'], 
                                       indent=2, 
                                       ensure_ascii=False
                                   )
                                   zip_file.writestr("brand_keywords_ai_insights.json", keywords_insights)
                           
                           # 3. Analisi per ogni piattaforma (JSON separati)
                           if has_analysis:
                               analysis_results = st.session_state.reviews_data['analysis_results']
                               
                               # File JSON per ogni piattaforma
                               for platform, analysis in analysis_results.items():
                                   if analysis:
                                       platform_name = platform.replace('_analysis', '')
                                       analysis_content = json.dumps(analysis, indent=2, ensure_ascii=False)
                                       zip_file.writestr(f"analysis_{platform_name}.json", analysis_content)
                               
                               # Analisi completa unificata
                               complete_analysis = json.dumps(analysis_results, indent=2, ensure_ascii=False)
                               zip_file.writestr("complete_multiplatform_analysis.json", complete_analysis)
                           
                           # 4. AI Insights completi
                           if has_ai and isinstance(st.session_state.reviews_data['ai_insights'], dict):
                               ai_complete = {
                                   'metadata': {
                                       'export_date': datetime.now().isoformat(),
                                       'platforms_analyzed': list(analysis_results.keys()) if has_analysis else [],
                                       'total_items_analyzed': sum(a.get('total', 0) for a in analysis_results.values() if isinstance(a, dict)) if has_analysis else 0
                                   },
                                   'ai_insights': st.session_state.reviews_data['ai_insights']
                               }
                               ai_content = json.dumps(ai_complete, indent=2, ensure_ascii=False)
                               zip_file.writestr("complete_ai_insights.json", ai_content)
                           
                           # 5. Report di riepilogo esteso
                           summary_lines = [
                               "BRAND INTELLIGENCE ANALYSIS ARCHIVE",
                               f"Generated: {datetime.now().strftime('%d/%m/%Y at %H:%M')}",
                               f"Tool: Reviews & Keywords Analyzer Multi-Platform v2.1",
                               "",
                               "PLATFORMS DATA COLLECTED:",
                               f"- Trustpilot Reviews: {len(st.session_state.reviews_data['trustpilot_reviews'])}",
                               f"- Google Reviews: {len(st.session_state.reviews_data['google_reviews'])}",
                               f"- TripAdvisor Reviews: {len(st.session_state.reviews_data['tripadvisor_reviews'])}",
                               f"- Extended Reviews (Yelp+): {st.session_state.reviews_data['extended_reviews']['total_count']}",
                               f"- Reddit Discussions: {len(st.session_state.reviews_data['reddit_discussions'])}",
                               f"- Brand Keywords: {len(st.session_state.reviews_data['brand_keywords']['raw_keywords'])}",
                               f"- TOTAL ITEMS: {tp_count + g_count + ta_count + ext_count + reddit_count + kw_count}",
                               "",
                               "ANALYSIS COMPLETED:",
                               f"- Multi-Platform Statistical Analysis: {'‚úÖ' if has_analysis else '‚ùå'}",
                               f"- AI Strategic Insights: {'‚úÖ' if has_ai else '‚ùå'}",
                               f"- Brand Keywords Analysis: {'‚úÖ' if has_keywords else '‚ùå'}",
                               "",
                               "FILES INCLUDED:",
                               "- multiplatform_reviews_data.csv: All reviews/discussions unified",
                               "- brand_keywords_data.csv: Brand search keywords data",
                               "- analysis_[platform].json: Platform-specific analysis results",
                               "- complete_multiplatform_analysis.json: Unified analysis results",
                               "- complete_ai_insights.json: AI strategic insights with metadata",
                               "- brand_keywords_ai_insights.json: Keywords-based brand insights",
                               "- archive_summary.txt: This summary file",
                               "",
                               "PLATFORM BREAKDOWN:"
                           ]
                           
                           # Aggiungi breakdown dettagliato se disponibile
                           if has_analysis:
                               for platform, analysis in analysis_results.items():
                                   if analysis and analysis.get('total', 0) > 0:
                                       platform_name = platform.replace('_analysis', '').title()
                                       summary_lines.extend([
                                           f"",
                                           f"{platform_name.upper()}:",
                                           f"  - Total Items: {analysis['total']}",
                                           f"  - Average Rating: {analysis.get('avg_rating', 0):.2f}/5",
                                           f"  - Positive Sentiment: {analysis.get('sentiment_percentage', {}).get('positive', 0):.1f}%",
                                           f"  - Top Theme: {analysis.get('top_themes', [['N/A', 0]])[0][0] if analysis.get('top_themes') else 'N/A'}"
                                       ])
                           
                           summary_lines.extend([
                               "",
                               "---",
                               "For support: michiamo@antoniodeluca.me",
                               "Tool Repository: Reviews Analyzer v2.0"
                           ])
                           
                           summary = '\n'.join(summary_lines)
                           zip_file.writestr("archive_summary.txt", summary)
                           
                           # 6. File con metadata JSON
                           metadata = {
                               'archive_info': {
                                   'creation_date': datetime.now().isoformat(),
                                   'tool_version': 'Brand Intelligence Analyzer v2.1',
                                   'total_platforms': len([p for p, a in analysis_results.items() if isinstance(a, dict) and a.get('total', 0) > 0]) if has_analysis else 0,
                                   'total_items': sum([
                                       tp_count, g_count, ta_count, ext_count, reddit_count, kw_count
                                   ])
                               },
                               'platform_summary': {}
                           }
                           
                           if has_analysis:
                               for platform, analysis in analysis_results.items():
                                   if analysis and analysis.get('total', 0) > 0:
                                       platform_name = platform.replace('_analysis', '')
                                       metadata['platform_summary'][platform_name] = {
                                           'total_items': analysis['total'],
                                           'avg_rating': analysis.get('avg_rating', 0),
                                           'sentiment_positive_pct': analysis.get('sentiment_percentage', {}).get('positive', 0)
                                       }
                           
                           if has_keywords:
                               metadata['keywords_summary'] = {
                                   'total_keywords': len(st.session_state.reviews_data['brand_keywords']['raw_keywords']),
                                   'has_ai_analysis': bool(st.session_state.reviews_data['brand_keywords']['ai_insights'])
                               }
                           
                           metadata_content = json.dumps(metadata, indent=2, ensure_ascii=False)
                           zip_file.writestr("archive_metadata.json", metadata_content)
                       
                       # Download
                       zip_buffer.seek(0)
                       st.download_button(
                           label="üì• Download Complete Brand Intelligence Archive",
                           data=zip_buffer.getvalue(),
                           file_name=f"brand_intelligence_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                           mime="application/zip",
                           use_container_width=True
                       )
                       
                       show_message("üì¶ Archivio Brand Intelligence completo generato con successo!", "success")
                       
                       # Mostra contenuto archivio
                       with st.expander("üìã Contenuto Archivio"):
                           st.markdown("""
                           **Files inclusi nell'archivio:**
                           - üìä `multiplatform_reviews_data.csv` - Dati unificati tutte le piattaforme
                           - üîç `brand_keywords_data.csv` - Keywords di brand analizzate
                           - üìà `analysis_[platform].json` - Analisi per singola piattaforma  
                           - üîÑ `complete_multiplatform_analysis.json` - Analisi cross-platform
                           - ü§ñ `complete_ai_insights.json` - AI insights con metadata
                           - üß† `brand_keywords_ai_insights.json` - Insights keywords brand
                           - üìã `archive_summary.txt` - Riepilogo leggibile
                           - ‚öôÔ∏è `archive_metadata.json` - Metadata strutturati
                           """)
                       
                   except Exception as e:
                       show_message(f"Errore nella creazione dell'archivio: {str(e)}", "error")

# Footer multi-platform
st.markdown("---")
st.markdown("""
<div style="text-align: center; padding: 20px; background: linear-gradient(135deg, var(--dark-purple) 0%, var(--primary-purple) 25%, var(--trustpilot-green) 50%, var(--google-blue) 75%, var(--tripadvisor-green) 100%); border-radius: 15px;">
    <p style="color: white; font-size: 1.2em; font-weight: 600;">üåç <strong>REVIEWS NLYZR</strong></p>
    <p style="color: white;">Reviews: Trustpilot ‚Ä¢ Google ‚Ä¢ TripAdvisor ‚Ä¢ Yelp ‚Ä¢ Reddit | Keywords: Google Ads</p>
    <p style="color: white;">Developed by Antonio De Luca ‚Ä¢ Powered by DataForSEO & OpenAI</p>
</div>
""", unsafe_allow_html=True)

# Sidebar Credits esteso
with st.sidebar:
    st.markdown("---")
    st.markdown("### üîß Sviluppato da")
    st.markdown("**Antonio Deluca**")
    st.markdown("üìß michiamo@antoniodeluca.me")
    
    st.markdown("### üåç Piattaforme v2.1")
    platform_badges = [
        create_platform_badge("Trustpilot"),
        create_platform_badge("Google"),
        create_platform_badge("TripAdvisor"),
        create_platform_badge("Yelp"),
        create_platform_badge("Reddit")
    ]
    for badge in platform_badges:
        st.markdown(badge, unsafe_allow_html=True)
    
# Aggiungi info Keywords
    if st.session_state.reviews_data['brand_keywords']['raw_keywords']:
        keywords_count = len(st.session_state.reviews_data['brand_keywords']['raw_keywords'])
        st.markdown(f'<div class="platform-badge">üîç Keywords: {keywords_count}</div>', unsafe_allow_html=True)
    
    st.markdown("### üîå Powered by")
    st.markdown("- DataForSEO Multi-Platform API")
    st.markdown("- DataForSEO Keywords API")
    st.markdown("- OpenAI GPT-4o-mini")
    st.markdown("- Streamlit + Plotly")
    st.markdown("- Cross-Platform Analytics")
    
    st.markdown("### üìä Session Stats")
    if 'session_start' not in st.session_state:
        st.session_state.session_start = datetime.now()
    
    session_duration = datetime.now() - st.session_state.session_start
    
    # Definisci tutti i count prima di usarli
    tp_count = len(st.session_state.reviews_data.get('trustpilot_reviews', []))
    g_count = len(st.session_state.reviews_data.get('google_reviews', []))
    ta_count = len(st.session_state.reviews_data.get('tripadvisor_reviews', []))
    ext_count = st.session_state.reviews_data.get('extended_reviews', {}).get('total_count', 0)
    reddit_count = len(st.session_state.reviews_data.get('reddit_discussions', []))
    kw_count = len(st.session_state.reviews_data.get('brand_keywords', {}).get('raw_keywords', []))
    
    total_items = tp_count + g_count + ta_count + ext_count + reddit_count + kw_count
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("‚è±Ô∏è Duration", f"{session_duration.seconds // 60}m")
    with col2:
        st.metric("üìä Items", total_items)

if __name__ == "__main__":
    logger.info("Reviews Analyzer Tool v2.0 avviato")
